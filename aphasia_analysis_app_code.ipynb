{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreekar0919/AphasiaDiagnosis/blob/LingoDx/aphasia_analysis_app_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1EUYQckpJDL",
        "outputId": "a13a4268-5802-473c-f931-0bfdb3771db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.35.14-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Collecting streamlit-lottie\n",
            "  Downloading streamlit_lottie-0.0.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.0)\n",
            "Collecting tenacity\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Collecting botocore<1.36.0,>=1.35.14 (from boto3)\n",
            "  Downloading botocore-1.35.14-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Collecting PyMuPDFb==1.24.10 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Collecting triton<3,>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.14->boto3) (2.0.7)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.5.15)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading boto3-1.35.14-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_lottie-0.0.5-py3-none-any.whl (802 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading botocore-1.35.14-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801360 sha256=4c4c5461657b19cd9a67725988644b47ffafb7331a5c46e75e75fc670fe6fabd\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: pydub, watchdog, triton, tenacity, smmap, python-docx, pyngrok, PyMuPDFb, jmespath, tiktoken, PyMuPDF, pydeck, gitdb, botocore, s3transfer, openai-whisper, gitpython, boto3, streamlit, streamlit-lottie\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed PyMuPDF-1.24.10 PyMuPDFb-1.24.10 boto3-1.35.14 botocore-1.35.14 gitdb-4.0.11 gitpython-3.1.43 jmespath-1.0.1 openai-whisper-20231117 pydeck-0.9.1 pydub-0.25.1 pyngrok-7.2.0 python-docx-1.1.2 s3transfer-0.10.2 smmap-5.0.1 streamlit-1.38.0 streamlit-lottie-0.0.5 tenacity-8.5.0 tiktoken-0.7.0 triton-2.3.1 watchdog-4.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok boto3 pandas plotly openpyxl tenacity PyMuPDF python-docx xlrd streamlit-lottie openai-whisper moviepy pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qu92URW_rrx",
        "outputId": "760f6f22-c1c8-4421-8e9c-d7d84d07b058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is running on: NgrokTunnel: \"https://94e9-34-125-131-151.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Set your ngrok authtoken here\n",
        "NGROK_AUTH_TOKEN = \"2jhxB5bZ9YCnzQPkebpqrxLPrgj_4wtRaRBErwDWXzNoNxkha\"\n",
        "\n",
        "def run_streamlit_with_ngrok():\n",
        "    # Set ngrok authtoken\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "    # Start ngrok tunnel\n",
        "    try:\n",
        "        public_url = ngrok.connect(addr=\"8501\", proto=\"http\", name=\"streamlit\")\n",
        "        print(f\"Streamlit app is running on: {public_url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up ngrok: {e}\")\n",
        "        return\n",
        "\n",
        "    # Run Streamlit app\n",
        "    os.system(\"streamlit run main.py &\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_streamlit_with_ngrok()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import boto3\n",
        "import json\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from io import BytesIO\n",
        "import openpyxl\n",
        "import fitz  # PyMuPDF\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from streamlit_lottie import st_lottie\n",
        "import requests\n",
        "import base64\n",
        "from botocore.exceptions import ClientError\n",
        "import whisper\n",
        "import tempfile\n",
        "import os\n",
        "from moviepy.editor import VideoFileClip\n",
        "from pydub import AudioSegment\n",
        "import re\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# AWS credentials\n",
        "\n",
        "AWS_ACCESS_KEY = \n",
        "AWS_SECRET_KEY = \n",
        "AWS_REGION = \"us-east-1\"\n",
        "\n",
        "\n",
        "# Initialize AWS clients\n",
        "s3 = boto3.client('s3',\n",
        "                  aws_access_key_id=AWS_ACCESS_KEY,\n",
        "                  aws_secret_access_key=AWS_SECRET_KEY,\n",
        "                  region_name=AWS_REGION)\n",
        "\n",
        "bedrock = boto3.client('bedrock-runtime',\n",
        "                       aws_access_key_id=AWS_ACCESS_KEY,\n",
        "                       aws_secret_access_key=AWS_SECRET_KEY,\n",
        "                       region_name=AWS_REGION)\n",
        "\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "\n",
        "\n",
        "# Helper functions\n",
        "\n",
        "\n",
        "files = {\n",
        "    \"intro\": \"/content/Therapies/Intro to Aphasia Therapy.pdf\",\n",
        "    \"anomia\": \"/content/Therapies/Anomia.pdf\",\n",
        "    \"utterances\": \"/content/Therapies/Utterances.pdf\",\n",
        "    \"preservation\": \"/content/Therapies/Preservation.pdf\",\n",
        "    \"mit\": \"/content/Therapies/Melodic Intonation Therapy.pdf\",\n",
        "    \"agrammatism\": \"/content/Therapies/Agrammatism.pdf\",\n",
        "    \"wernicke\": \"/content/Therapies/Wernicke’s Aphasia.pdf\",\n",
        "    \"ac\": \"/content/Therapies/Auditory Comprehension.pdf\",\n",
        "    \"misc\": \"/content/Therapies/Miscellaneous.pdf\",\n",
        "    \"example_report\": \"/content/XX dx report (1) (1) (2).pdf\",\n",
        "    \"example_patients\": \"/content/aphasiapatient - ENGLISH - aphasiapatient (1).pdf\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_lottie_url(url: str):\n",
        "    r = requests.get(url)\n",
        "    if r.status_code != 200:\n",
        "        return None\n",
        "    return r.json()\n",
        "\n",
        "def read_pdf(file):\n",
        "    if isinstance(file, str):\n",
        "        document = fitz.open(file)\n",
        "    else:\n",
        "        document = fitz.open(stream=file.read(), filetype=\"pdf\")\n",
        "\n",
        "    text = \"\"\n",
        "    for page_num in range(len(document)):\n",
        "        page = document.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "intro = read_pdf(files[\"intro\"])\n",
        "anomia = read_pdf(files[\"anomia\"])\n",
        "utterances = read_pdf(files[\"utterances\"])\n",
        "preservation = read_pdf(files[\"preservation\"])\n",
        "mit = read_pdf(files[\"mit\"])\n",
        "agrammatism = read_pdf(files[\"agrammatism\"])\n",
        "wernicke = read_pdf(files[\"wernicke\"])\n",
        "ac = read_pdf(files[\"ac\"])\n",
        "misc = read_pdf(files[\"misc\"])\n",
        "example_report = read_pdf(files[\"example_report\"])\n",
        "example_patients = read_pdf(files[\"example_patients\"])\n",
        "\n",
        "palpa = \"\"\"The PALPA (Psycholinguistic Assessment of Language Processing in Aphasia) is a comprehensive tool used by speech-language pathologists and researchers to assess various aspects of language processing in individuals with aphasia. It consists of a series of tasks designed to evaluate different language functions, such as comprehension, repetition, naming, and more nuanced aspects like phonological and semantic processing.\n",
        "\n",
        "Overview of PALPA Subscores\n",
        "Comprehension Subscores:\n",
        "\n",
        "Single Word Comprehension: Assesses the ability to understand individual words.\n",
        "Sentence Comprehension: Evaluates comprehension of syntactically complex sentences.\n",
        "Repetition Subscores:\n",
        "\n",
        "Word Repetition: Measures the ability to repeat single words accurately.\n",
        "Phrase Repetition: Assesses repetition of short phrases or sentences.\n",
        "Naming Subscores:\n",
        "\n",
        "Object Naming: Tests the ability to name objects, often categorized by semantic category (e.g., animals, tools).\n",
        "Action Naming: Evaluates naming of actions or verbs.\n",
        "Responsive Naming: Assesses naming abilities based on descriptions or cues.\n",
        "Phonological Processing Subscores:\n",
        "\n",
        "Phoneme Discrimination: Tests the ability to distinguish between similar phonemes.\n",
        "Phonological Blending: Assesses the ability to blend phonemes into meaningful units.\n",
        "Semantic Processing Subscores:\n",
        "\n",
        "Word-to-Picture Matching: Evaluates matching words to corresponding pictures.\n",
        "Category Fluency: Measures the ability to generate words within a semantic category.\n",
        "Synonym Judgment: Assesses understanding of semantic relationships between words.\n",
        "\n",
        "The subscores in PALPA refer to the specific domains or components of language that are assessed within each task. These subscores help clinicians and researchers pinpoint the specific areas of language impairment in individuals with aphasia. For example, in a naming task, subscores might indicate the accuracy of naming objects in different categories (e.g., animals, tools) or the types of errors made during naming attempts (e.g., phonemic errors, semantic paraphasias).\n",
        "\n",
        "Each subscore provides detailed information about the nature and severity of language impairments, which is crucial for developing tailored treatment plans and understanding the underlying mechanisms of aphasia in each individual.\n",
        "\"\"\"\n",
        "\n",
        "bnt = \"\"\" The Boston Naming Test (BNT) is a standardized neuropsychological assessment designed to evaluate the ability to name objects presented in picture format. Developed by Kaplan, Goodglass, and Weintraub, it is widely used in clinical settings to assess language impairments, particularly in individuals with aphasia and other neurological conditions affecting language.\n",
        "\n",
        "Key Features of the BNT:\n",
        "\n",
        "1. Test Format:\n",
        "   - The BNT consists of a set of 60 line drawings of objects. These drawings range from common items (e.g., animals, tools) to more complex or less familiar objects.\n",
        "   - Participants are asked to name each picture aloud.\n",
        "\n",
        "2. Administration:\n",
        "   - The test is typically administered one-on-one by a clinician or trained professional.\n",
        "   - Each picture is presented individually, and the participant's responses are recorded for scoring purposes.\n",
        "\n",
        "3. Scoring:\n",
        "   - Scores on the BNT are based on the number of correctly named items out of 60.\n",
        "   - Errors made during naming are categorized into different types:\n",
        "     - Semantic Errors: Naming related but incorrect items (e.g., calling a \"lion\" a \"tiger\").\n",
        "     - Phonemic Paraphasias: Naming errors where the response is phonologically related to the correct name (e.g., saying \"tiger\" instead of \"lion\").\n",
        "     - Circumlocutions: Describing the object instead of naming it.\n",
        "     - Perseverations: Repeating the same incorrect response for different items.\n",
        "\n",
        "4. Clinical Application:\n",
        "   - Diagnostic Use: The BNT helps clinicians identify and classify language impairments, particularly deficits in object naming.\n",
        "   - Treatment Planning: Results from the BNT guide the development of targeted intervention strategies. For example, if a patient shows a pattern of semantic errors, therapy might focus on semantic feature analysis or semantic association techniques.\n",
        "   - Progress Monitoring: Regular administration of the BNT allows clinicians to track changes in naming abilities over time, assessing the effectiveness of interventions and adjusting treatment plans accordingly.\n",
        "   - Research Tool: Beyond clinical use, the BNT is also utilized in research settings to investigate language processing and cognitive functions across different populations.\n",
        "\n",
        "5. Normative Data: Normative data for the BNT provides benchmarks for comparing individual performance to age- and education-matched peers, enhancing the interpretation of test results in clinical and research contexts.\n",
        "\n",
        "Overall, the Boston Naming Test is a valuable tool for assessing and understanding naming abilities in individuals with aphasia and other language disorders, providing critical information for treatment planning and research in neuropsychology and speech-language pathology.\"\"\"\n",
        "\n",
        "wab = \"\"\"The WAB (Western Aphasia Battery) is a comprehensive and widely used assessment tool designed to evaluate language abilities in individuals with aphasia. Developed by Kertesz in 1982 and revised in 2006, the WAB assesses various aspects of language function to provide a detailed profile of language impairment. Here’s an overview of the WAB and its clinical application:\n",
        "\n",
        "Key Features of the WAB:\n",
        "\n",
        "1. Components:\n",
        "Subtest 1. Spontaneous speech\n",
        "Task\tDescription\tScoring\n",
        "1. Conversational question:\tThe client verbally responds to 6 personal questions.\tThere are 2 scoring sections for Spontaneous speech: Information content and Fluency, grammatical competence, and paraphasias.For Information content:10 points are given if all 6 questions were answered correctly with sentences of normal length and complexity, as well as a reasonably complete description of the picture. Nine points are given if all 6 questions were answered correctly, as well as an almost complete description of the picture. Eight points are given if 5 questions were answered correctly, with an incomplete description of the picture. Seven points are given if 4 questions were answered correctly, as well as at least 6 items in the picture being mentioned. Six points are given if 4 questions were answered correctly, as well as some response to the picture. Five points are given if 3 questions were answered correctly, as well as some response to the picture. Four points are given if 3 questions were answered correctly. Three points are given if 2 questions were answered correctly. Two points are given if 1 question is answered correctly. One point is given for incomplete responses. No points are given for no information.\n",
        "For Fluency, grammatical competence, and paraphasias:\n",
        "\n",
        "Scoring is from 0 to 10. Ten points are given for sentences of normal length and complexity, without slowing down, stopping, or articulatory difficulty, and no paraphasias. As sentences become less lengthy and complex, more slow, and with paraphasias, less points are given.\n",
        "\n",
        "Please see the test manual for further information.\n",
        "\n",
        "2. Personal description:\tThe client describes a picture in the stimulus book.\n",
        "Subtest 2. Auditory verbal comprehension\n",
        "Task\tDescription\tScoring\n",
        "1. Yes/No questions:\tThe client must answer personal, environment and general questions with a Yes or No.\tIf the client corrects themselves, the last answer is scored. Three points are given for each correct answer. If the answer is ambiguous, 0 points are given. The examiner also marks whether the response was verbal, gestural, or eye blink.\n",
        "2. Auditory word recognition:\tThe client is shown 6 real objects, as well as cards of pictured objects, forms, letters, numbers and colors. The client must point to what the examiner says. There are 6 items in each category: real objects, drawn objects, forms, letters, numbers, colors, furniture, body parts, fingers and right-left body parts.\tOne point is given to each item pointed to correctly. For the right-left category, the client must get both the side and the body part correct to receive the point. Maximum score is 60.\n",
        "3. Sequential commands:\tThe client must execute 11 commands that increase in difficulty and length.\tThere are scores associated to the segments in each of the listed commands. Points are given for each correct execution. Please see the test booklet for further information. Maximum score is 80.\n",
        "Subtest 3. Repetition\n",
        "Description\tScoring\n",
        "1. The client must repeat words, phrases and sentences of increasing difficulty (from single words to a complex sentence), with a total of 15 items.\tAs length and difficulty increases, more points are given to the client for correct repetition. Two points are given if an item is incompletely repeated. One point is taken off for errors in the sequence of words, or for every literal paraphasia. Maximum score is 100.Scoring takes phonemic errors into account by permitting partial credit.\n",
        "Subtest 4. Naming and word finding\n",
        "Task\tDescription\tScoring\n",
        "1. Object naming:\tShow 20 objects from various categories to client, and ask them to name them one at a time.\tIf there is no response to the visual stimulus, the examiner allows the client to touch the stimulus. If there still isn’t a correct response, the examiner presents a phonemic or semantic cue. A maximum of 20 seconds if given to the client to respond. Three points are given if named correctly (or with a minor articulatory error); 2 points are given for a recognizable phonemic paraphasia; 1 point is given if the client needed a tactile or phonemic cue to respond correctly. Maximum score is 60.Permits sequential tactile and phonemic cueing for the patient who cannot provide the proper name upon initial confrontation with the object, yielding qualitatively useful information without sacrificing the integrity of the scoring system.\n",
        "2. Word fluency:\tThe client must name as many animals as they can in one minute.\tOne point is given for each animal names, even if it is distorted by literal paraphasia. Maximum score is 20.\n",
        "3. Sentence completion:\tThe client must complete sentences read to them.\tTwo points are given for correct responses; 1 point is given for phonemic paraphasias. Reasonable alternatives are accepted. Maximum score is 10.\n",
        "4. Responsive speech:\tThe client must answer 5 sentences read to them.\tTwo points are given for acceptable responses; 1 point is given for phonemic paraphasias. Maximum score is 10.\n",
        "\n",
        "2. Administration:\n",
        "   - The WAB is administered by a trained clinician in a structured manner, usually over multiple sessions.\n",
        "   - Each component is evaluated through standardized tasks and scoring criteria.\n",
        "\n",
        "3. Scoring:\n",
        "   - Scores on the WAB provide an overall Aphasia Quotient (AQ), which reflects the severity and type of aphasia.\n",
        "   - Subscores are also provided for each component (Spontaneous Speech, Auditory Verbal Comprehension, Repetition, Naming), offering detailed insights into specific language deficits.\n",
        "\n",
        "4. Clinical Application:\n",
        "   - Diagnostic Use: The WAB helps clinicians diagnose aphasia and classify its type and severity based on standardized criteria.\n",
        "   - Treatment Planning: Results from the WAB guide the development of personalized treatment goals and strategies. For instance, if a patient scores low on auditory comprehension, therapy might focus on auditory discrimination and comprehension tasks.\n",
        "   - Progress Monitoring: Regular administration of the WAB allows clinicians to track changes in language abilities over time, assessing the effectiveness of interventions and modifying treatment plans as needed.\n",
        "   - Research Tool: The WAB is also utilized in research settings to study language recovery, neuroplasticity, and the effectiveness of different therapeutic interventions.\n",
        "\n",
        "\n",
        "\n",
        "5. Normative Data: Normative data for the WAB provides benchmarks for comparing individual performance to age- and education-matched peers, enhancing the interpretation of test results in clinical and research contexts.\n",
        "\n",
        "Overall, the Western Aphasia Battery is a comprehensive tool for assessing and understanding the complex language impairments associated with aphasia, providing valuable information for diagnosis, treatment planning, and research in the fields of neuropsychology and speech-language pathology.\"\"\"\n",
        "\n",
        "information = f\"\"\"\n",
        "Broca's Aphasia:\n",
        "- Spontaneous speech: Non-fluent, effortful, telegraphic\n",
        "- Auditory comprehension: Relatively preserved, especially for simple material\n",
        "- Repetition: Impaired\n",
        "- Naming: Difficult, with frequent pauses\n",
        "- Reading: Often preserved for single words, difficulty with sentences\n",
        "- Writing: Severely impaired, similar to speech output\n",
        "\n",
        "Typical errors: Agrammatism, word-finding difficulties, articulation problems\n",
        "\n",
        "Associated brain region: Posterior inferior frontal gyrus (Broca's area)\n",
        "\n",
        "Case example: A 55-year-old right-handed man presents with halting, effortful speech following a left frontal lobe stroke. He can understand simple commands but struggles to produce complete sentences, often omitting function words and inflections.\n",
        "\n",
        "Wernicke's Aphasia:\n",
        "- Spontaneous speech: Fluent, often with excessive output\n",
        "- Auditory comprehension: Severely impaired\n",
        "- Repetition: Impaired\n",
        "- Naming: Impaired, with semantic paraphasias\n",
        "- Reading: Often impaired, especially for comprehension\n",
        "- Writing: Impaired, with semantic errors and jargon\n",
        "\n",
        "Typical errors: Semantic paraphasias, neologisms, jargon\n",
        "\n",
        "Associated brain region: Posterior superior temporal gyrus (Wernicke's area)\n",
        "\n",
        "Case example: A 70-year-old woman presents with fluent but largely incomprehensible speech following a left temporal lobe stroke. She speaks at length but with little meaningful content, and has significant difficulty understanding even simple commands.\n",
        "\n",
        "Conduction Aphasia:\n",
        "- Spontaneous speech: Fluent with phonemic paraphasias\n",
        "- Auditory comprehension: Relatively preserved\n",
        "- Repetition: Severely impaired\n",
        "- Naming: Mildly impaired, with phonemic errors\n",
        "- Reading: Often preserved, especially for comprehension\n",
        "- Writing: Impaired, with phonemic errors\n",
        "\n",
        "Typical errors: Frequent phonemic paraphasias, repetition attempts and self-corrections\n",
        "\n",
        "Associated brain region: Arcuate fasciculus or left supramarginal gyrus\n",
        "\n",
        "Case example: A 62-year-old woman presents with fluent speech but significant difficulty repeating words and phrases. She understands spoken language well but makes frequent sound-based errors in her speech, often attempting to correct herself.\n",
        "\n",
        "Global Aphasia:\n",
        "- Spontaneous speech: Severely impaired, often limited to stereotyped utterances\n",
        "- Auditory comprehension: Severely impaired\n",
        "- Repetition: Severely impaired\n",
        "- Naming: Severely impaired\n",
        "- Reading: Severely impaired\n",
        "- Writing: Severely impaired\n",
        "\n",
        "Typical errors: Minimal meaningful verbal output, severe impairment across all language domains\n",
        "\n",
        "Associated brain region: Extensive damage to perisylvian language areas\n",
        "\n",
        "Case example: A 75-year-old man presents with almost no meaningful speech output following a large left hemisphere stroke. He is unable to follow commands, name objects, or engage in any form of written language.\n",
        "\n",
        "Anomic Aphasia:\n",
        "- Spontaneous speech: Fluent but with word-finding pauses\n",
        "- Auditory comprehension: Preserved\n",
        "- Repetition: Relatively preserved\n",
        "- Naming: Significantly impaired\n",
        "- Reading: Often preserved\n",
        "- Writing: Mild to moderate impairment, mainly in word retrieval\n",
        "\n",
        "Typical errors: Frequent word-finding difficulties, circumlocutions\n",
        "\n",
        "Associated brain region: Various, often involving the angular gyrus or temporal-parietal junction\n",
        "\n",
        "Case example: A 58-year-old woman presents with fluent speech but frequent pauses as she struggles to retrieve specific words, especially nouns. Her comprehension and repetition abilities are intact.\n",
        "\n",
        "Transcortical Sensory Aphasia:\n",
        "- Spontaneous speech: Fluent but often empty or irrelevant\n",
        "- Auditory comprehension: Impaired\n",
        "- Repetition: Preserved (key distinguishing feature)\n",
        "- Naming: Impaired\n",
        "- Reading: Impaired comprehension\n",
        "- Writing: Impaired\n",
        "\n",
        "Typical errors: Poor comprehension with preserved repetition, semantic paraphasias\n",
        "\n",
        "Associated brain region: Watershed area between middle cerebral and posterior cerebral arteries\n",
        "\n",
        "Case example: A 68-year-old man presents with fluent but often irrelevant speech. He has difficulty understanding complex commands but can repeat even long sentences accurately.\n",
        "\n",
        "Transcortical Motor Aphasia:\n",
        "- Spontaneous speech: Non-fluent, reduced output\n",
        "- Auditory comprehension: Relatively preserved\n",
        "- Repetition: Preserved\n",
        "- Naming: Impaired\n",
        "- Reading: Often preserved for comprehension\n",
        "- Writing: Impaired\n",
        "\n",
        "Typical errors: Reduced speech initiation, preserved repetition\n",
        "\n",
        "Associated brain region: Frontal lobe, anterior or superior to Broca's area\n",
        "\n",
        "Case example: A 72-year-old woman presents with reduced speech output and difficulty initiating conversation. However, she can repeat phrases and sentences without difficulty and shows good comprehension.\n",
        "1. Fluency vs. Non-fluency\n",
        "   - Fluent: Wernicke's, Conduction, Anomic, Transcortical Sensory\n",
        "   - Non-fluent: Broca's, Global, Transcortical Motor\n",
        "\n",
        "2. Comprehension\n",
        "   - Good: Broca's, Conduction, Anomic, Transcortical Motor\n",
        "   - Poor: Wernicke's, Global, Transcortical Sensory\n",
        "\n",
        "3. Repetition\n",
        "   - Impaired: Broca's, Wernicke's, Conduction, Global\n",
        "   - Preserved: Anomic, Transcortical Sensory, Transcortical Motor\n",
        "\n",
        "4. Naming\n",
        "   - Severely Impaired: Wernicke's, Global, Anomic\n",
        "   - Moderately Impaired: Broca's, Conduction, Transcortical types\n",
        "\n",
        "Every type of aphasia is equally common and it differs on a patient by patient basis.\n",
        "Provide your classification and a detailed justification based on the patient's performance across all domains.\n",
        "\"\"\"\n",
        "cleaned_content = \"\"\n",
        "\n",
        "# Format the answer\n",
        "answer_info = f\"\"\"\n",
        "Information: {cleaned_content}.\n",
        "\n",
        "When I refer to the spreadsheet, use the {example_patients} file to compare the transcript I am giving you. This is a file of aphasic patients of all types, ages, genders, and range of severity. Based on your comparison to these patients, determine the aphasia type and WAB score.\n",
        "\n",
        "Can you analyze the entire spreadsheet. And every row\n",
        "Compare the transcript to the spreadsheet. Give me the top 3 rows that you think align with this patient in transcript. Look only at the PAR lines for this\n",
        "Look only at the PAR lines for this. Each row has language, gender, aphasia type, WAB Score, Transcript. Compare the symptoms of the transcript to the last column of each row in this file to find which symptoms match the spreadsheet. Then, look at the other information.\n",
        "List:\n",
        "Look only at the PAR lines for this. I want you to compare the entire sections. Look towards the ending of the transcript in fact. there is more content there\n",
        "(row  in the spreadsheet; Display the first 3 lines and the line that you think connects the transcript the best)\n",
        "(row  in the spreadsheet; Display the first 3 lines and the line that you think connects the transcript the best)\n",
        "(row  in the spreadsheet; Display the first 3 lines and the line that you think connects the transcript the best)\n",
        "\n",
        "Symptoms:\n",
        "You seem to be confusing word retreival issues and paraphasias/neologisms/Comprehension issues. Try to fixt this\n",
        "\n",
        "\n",
        "1. Fluency of speech: Is the speech effortful and non-fluent (like in Broca's aphasia) or more fluent but with errors (like in conduction or Wernicke's aphasia)? (number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "2. Comprehension abilities: How well does the patient understand spoken language? This helps differentiate receptive (e.g. Wernicke's) from expressive (e.g. Broca's) aphasias.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "3. Repetition skills: Ability to repeat words and phrases is a key diagnostic feature, particularly impaired in conduction aphasia.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "4. Naming abilities: Word-finding difficulties are common in many aphasias, but the nature and severity can vary.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "5. Presence and types of paraphasias: Phonemic paraphasias (sound errors) vs. semantic paraphasias (meaning-related errors) can point to different aphasia types.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "6. Awareness of errors: Whether the patient recognizes and attempts to correct their errors.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "7. Agrammatism: The degree to which grammatical structure is impaired.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "8. Automatic speech: Ability to produce overlearned phrases or sequences.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "9. Reading and writing abilities: These can be differentially affected in various aphasia types.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "10. Overall pattern of strengths and weaknesses across language domains.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "For accurate diagnosis, it's crucial to consider the full pattern of deficits and preserved abilities across all these areas, rather than relying too heavily on any single feature. A comprehensive language assessment considering all these factors is essential for proper aphasia classification.\n",
        "\n",
        "Symptom Severity Rating:\n",
        "Rate the following factors on a scale of 0-10:\n",
        "\n",
        "Fluency: (insert score here; scale of 0-10)\n",
        "Comprehension: (insert score here; scale of 0-10)\n",
        "Repetition: (insert score here; scale of 0-10)\n",
        "Naming: (insert score here; scale of 0-10)\n",
        "\n",
        "Global Aphasia\n",
        "\n",
        "Fluency: 0-5\n",
        "Comprehension: 0-3.9\n",
        "Repetition: 0-4.9\n",
        "Naming: 0-6\n",
        "\n",
        "\n",
        "Broca's Aphasia\n",
        "\n",
        "Fluency: 0-9\n",
        "Comprehension: 5-10\n",
        "Repetition: 0-6\n",
        "Naming: 0-8\n",
        "\n",
        "Wernicke's Aphasia\n",
        "\n",
        "Fluency: 0-3\n",
        "Comprehension: 0-9\n",
        "Repetition: 3-10\n",
        "Naming: 0-6\n",
        "\n",
        "\n",
        "Transcortical Motor Aphasia\n",
        "\n",
        "Fluency: 0-5\n",
        "Comprehension: 4-10\n",
        "Repetition: 8-10\n",
        "Naming: 0-8\n",
        "\n",
        "\n",
        "Transcortical Sensory Aphasia\n",
        "\n",
        "Fluency: 5-10\n",
        "Comprehension: 0-6.9\n",
        "Repetition: 8-10\n",
        "Naming: 0-9\n",
        "\n",
        "\n",
        "Mixed Transcortical Aphasia\n",
        "\n",
        "Fluency: 5-10\n",
        "Comprehension: 0-6.9\n",
        "Repetition: 8-10\n",
        "Naming: 0-9\n",
        "\n",
        "\n",
        "Conduction Aphasia\n",
        "\n",
        "Fluency: 5-10\n",
        "Comprehension: 7-10\n",
        "Repetition: 0-8\n",
        "Naming: 0-9\n",
        "\n",
        "Anomic Aphasia\n",
        "\n",
        "Fluency: 7-10\n",
        "Comprehension: 8-10\n",
        "Repetition: 8-10\n",
        "Naming: 0-9\n",
        "\n",
        "Aphasia Classification:\n",
        "1. Is speech fluent?\n",
        "A fluency disorder is an interruption in the flow of speaking characterized by atypical rate, rhythm, and disfluencies (e.g., repetitions of sounds, syllables, words, and phrases; sound prolongations; and blocks), which may also be accompanied by excessive tension, speaking avoidance, struggle behaviors, and secondary mannerisms (American Speech-Language-Hearing Association [ASHA], 1993). People with fluency disorders also frequently experience psychological, emotional, social, and functional impacts as a result of their communication disorder (Tichenor & Yaruss, 2019a).\n",
        "Make sure that you use the timestamps at the end of the transcripts to do this.\n",
        "   Yes -> Check comprehension\n",
        "   No -> Check comprehension for non-fluent types\n",
        "\n",
        "2. Fluent types:\n",
        "   - Poor comprehension, poor repetition -> Wernicke's\n",
        "   - Poor comprehension, good repetition -> Transcortical Sensory\n",
        "   - Good comprehension, poor repetition -> Conduction\n",
        "   - Good comprehension, good repetition -> Anomic\n",
        "\n",
        "3. Non-fluent types:\n",
        "   - Poor comprehension -> Global\n",
        "   - Good comprehension, poor repetition -> Broca's\n",
        "   - Good comprehension, good repetition -> Transcortical Motor\n",
        "\n",
        "Aphasia Classification Trial: (insert type of aphasia)\n",
        "\n",
        "Provide your classification with detailed justification based on performance across all domains.\n",
        "If all of the symptoms are less than 7 occurances, there is no aphasia\n",
        "It is important to look at not just the symptoms but thte content of the speech too. Is what the patient is saying make sense? Do they loose track of the topic? Are they frustrated?\n",
        "Initial Aphasia Diagnosis:\n",
        "Provide 4 types of aphasia it could be. Transcortical Motor Aphasia. Don't forget about  Wernicke's aphasia orGlobal aphasia or Transcortical Motor Aphasia or Transcortical Sensory Aphasia\n",
        "Initial Aphasia Types. For each of these types, compare back to the spreadsheet and check this transcript agaiinst every one of the transcripts for that type of aphasia. I dont\n",
        "Wernicke's Aphasia\n",
        "(insert type of aphasia or no aphasia)\n",
        "(insert type of aphasia or no aphasia)\n",
        "Considerations for Alternate Aphasias:\n",
        "List reasons for considering each alternate aphasia. Include detailed comparisons and rationale.\n",
        "Reevaluate the initial diagnosis if substantial evidence supports an alternate type.\n",
        "Type of aphasia: Present this in the format of \"Type of Aphasia: (insert aphasia type here)\"\n",
        "\n",
        "Provide a confidence score as well. If confidence is below 90% it is another type of aphasia.\n",
        "Keep trying to figure it out.\n",
        "\n",
        "Compare the transcript to the spreadsheet to determine aphasia type and WAB score.\n",
        "\n",
        "WAB Score Determination:\n",
        "\n",
        "Spontaneous Speech:\n",
        "Content\n",
        "Fluency\n",
        "\n",
        "\n",
        "Auditory Verbal Comprehension:\n",
        "Yes/No Questions\n",
        "Auditory Word Recognition\n",
        "\n",
        "\n",
        "Sequential Commands\n",
        "Repetition:\n",
        "Words\n",
        "Phrases\n",
        "Sentences\n",
        "\n",
        "\n",
        "Naming and Word Finding:\n",
        "Object Naming\n",
        "Word Fluency\n",
        "Sentence Completion\n",
        "Responsive Speech\n",
        "\n",
        "\n",
        "Aphasia Quotient (AQ): Overall score indicating the severity of aphasia.\n",
        "\n",
        "\n",
        "1. Start at WAB score of 5; not 50 because wab can be lower than 50\n",
        "2. Increase in 10-point intervals, comparing to the spreadsheet. Go all the way to 100\n",
        "3. Provide reasoning for each step\n",
        "4. When a suitable interval is found after going all the way to 100, refine by 5-point, then 1-point increments, then 0.1 point increments.\n",
        "5. Remember: WAB scores can be below 60 or above 93.8 (no aphasia)\n",
        "6. Determine a score based on the the following studies: The WAB has four subdomains: (1) spontaneous speech; (2) auditory comprehension; (3) repetition; and (4) naming designed to determine the presence of aphasia and judge the type of linguistic deficit and measure the severity of language impairment. The full score of spontaneous speech is 20, including fluency and content of information. The 200 points of auditory comprehension consist of 60 points of Yes–No questions, 60 points of auditory word recognition, and 80 points of sequential commands. The total score of repetition is 100. A total of 100 points are given for naming, including 60 points for object naming, 20 points for fluency of words, 10 points for sentence completion, and 10 points for responsive speech. The calculation formula of the aphasia quotient is “AQ = (Spontaneous + Comprehension ÷ 20 + Repetition ÷ 10 + Naming ÷ 10) × 2”. All of the items result in a range of possible scores from 0 to 100. Combined with the clinical data of stroke patients, those whose aphasia quotient is less than 93.8 can be judged as aphasia, and the smaller the aphasia quotient, the more serious the aphasia. In addition, the WAB-AQ is commonly used to measure recovery, although there is a discrepancy between clinical impression and WAB in the classification of aphasia, the superiority of WAB is that it can quantify language damage.\n",
        "7. Determine a score by comparing this patient with the participants in the spreadsheet.\n",
        "8. Compare the 3 scores and determine a final score.\n",
        "\n",
        "Show your thoughts below:\n",
        "WAB Score 1:\n",
        "WAB Score 2:\n",
        "WAB Score 3:\n",
        "\n",
        "WAB Score: Present this in the format of \"Estimated WAB Score: (insert number on scale of 0-100 here)\". Note that WAB scores can range widely and are not limited to 50-80.\n",
        "IMPORTANT: WAB SCORE IS NOT RELATED TO TYPE OF APHASIA\n",
        "\n",
        "Final Type of aphasia: Based on the WAB score and the original aphasia type, make any changes that you think would be mandatory. If you are borderline 93.8, check if the no aphasia option makes sense. Use the spreadsheet\n",
        "\n",
        "Treatment Suggestions:\n",
        "Provide treatment suggestions in a list, with a description for each therapy. Include a detailed explanation for choosing each treatment, citing the aphasia manual and patient symptoms.\n",
        "\n",
        "\n",
        "Explanation:\n",
        "(Provide a detailed explanation here for the therapist, ensuring it is useful and practical, citing the manual where appropriate).\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def excel_to_json(file):\n",
        "    data = {}\n",
        "    testing_dates = {}\n",
        "\n",
        "    try:\n",
        "        workbook = openpyxl.load_workbook(file, data_only=True)\n",
        "        logger.info(f\"Workbook loaded successfully. Sheets: {workbook.sheetnames}\")\n",
        "\n",
        "        for sheet in workbook.worksheets:\n",
        "            logger.info(f\"Processing sheet: {sheet.title}\")\n",
        "                        # Step 1: Identify date columns\n",
        "            date_columns = {}\n",
        "            for col in range(1, sheet.max_column + 1):\n",
        "                cell_value = sheet.cell(row=1, column=col).value\n",
        "                logger.debug(f\"Column {col}, Header: {cell_value}\")\n",
        "                if isinstance(cell_value, str) and \"Date:\" in cell_value:\n",
        "                    category, date_str = cell_value.split(\"Date:\")\n",
        "                    category = category.strip()\n",
        "                    date_str = date_str.strip()\n",
        "                    try:\n",
        "                        date = datetime.strptime(date_str, \"%m/%Y\").date().isoformat()\n",
        "                        date_columns[col] = (category, date)\n",
        "                        if category not in testing_dates:\n",
        "                            testing_dates[category] = []\n",
        "                        testing_dates[category].append(date)\n",
        "                        logger.info(f\"Found date column: {category}, {date}\")\n",
        "                    except ValueError:\n",
        "                        logger.warning(f\"Could not parse date: {date_str}\")\n",
        "\n",
        "            logger.info(f\"Identified date columns: {date_columns}\")\n",
        "\n",
        "            # Step 2: Process rows based on identified date columns\n",
        "            current_main_category = None\n",
        "            current_section = None\n",
        "            current_subsection = None\n",
        "\n",
        "            for row_idx, row in enumerate(sheet.iter_rows(min_row=2, values_only=True), start=2):\n",
        "                if not any(row):\n",
        "                    continue\n",
        "\n",
        "                logger.debug(f\"Processing row {row_idx}: {row}\")\n",
        "\n",
        "                # Check if this row is a main category\n",
        "                if row[0] and isinstance(row[0], str) and row[0] not in date_columns:\n",
        "                    current_main_category = row[0]\n",
        "                    current_section = None\n",
        "                    current_subsection = None\n",
        "                    logger.info(f\"New main category: {current_main_category}\")\n",
        "                    continue\n",
        "\n",
        "                # Process data for each date column\n",
        "                for col, (category, date) in date_columns.items():\n",
        "                    if date not in data:\n",
        "                        data[date] = {}\n",
        "                    if category not in data[date]:\n",
        "                        data[date][category] = {}\n",
        "\n",
        "                    if current_main_category:\n",
        "                        if current_main_category not in data[date][category]:\n",
        "                            data[date][category][current_main_category] = {}\n",
        "\n",
        "                    # Identify sections and subsections\n",
        "                    if row[1] and not row[2]:\n",
        "                        current_section = row[1]\n",
        "                        current_subsection = None\n",
        "                        logger.debug(f\"New section: {current_section}\")\n",
        "                    elif row[1] and row[2]:\n",
        "                        current_subsection = row[1]\n",
        "                        logger.debug(f\"New subsection: {current_subsection}\")\n",
        "\n",
        "                    # Process test scores\n",
        "                    if row[1] and row[2]:\n",
        "                        key = row[1]\n",
        "                        max_score = row[2]\n",
        "                        raw_score = row[col] if len(row) > col else None\n",
        "\n",
        "                        if raw_score is not None:\n",
        "                            value = {\n",
        "                                \"Max Score\": parse_value(max_score),\n",
        "                                \"Raw Score\": parse_value(raw_score)\n",
        "                            }\n",
        "                            logger.debug(f\"Processed score: {key} - {value}\")\n",
        "\n",
        "                            if current_main_category:\n",
        "                                if current_section not in data[date][category][current_main_category]:\n",
        "                                    data[date][category][current_main_category][current_section] = {}\n",
        "                                if current_subsection:\n",
        "                                    if current_subsection not in data[date][category][current_main_category][current_section]:\n",
        "                                        data[date][category][current_main_category][current_section][current_subsection] = {}\n",
        "                                    data[date][category][current_main_category][current_section][current_subsection][key] = value\n",
        "                                else:\n",
        "                                    data[date][category][current_main_category][current_section][key] = value\n",
        "                            else:\n",
        "                                if current_section not in data[date][category]:\n",
        "                                    data[date][category][current_section] = {}\n",
        "                                if current_subsection:\n",
        "                                    if current_subsection not in data[date][category][current_section]:\n",
        "                                        data[date][category][current_section][current_subsection] = {}\n",
        "                                    data[date][category][current_section][current_subsection][key] = value\n",
        "                                else:\n",
        "                                    data[date][category][current_section][key] = value\n",
        "\n",
        "        # Clean the data structure\n",
        "        data = clean_dict(data)\n",
        "        logger.info(\"Data processing completed\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"An error occurred: {str(e)}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "    return data, testing_dates\n",
        "\n",
        "def parse_value(value):\n",
        "    if value is None or value == '':\n",
        "        return None\n",
        "    if isinstance(value, (int, float)):\n",
        "        return value\n",
        "    if isinstance(value, str):\n",
        "        if value.replace('.', '').isdigit():\n",
        "            return float(value) if '.' in value else int(value)\n",
        "        elif value.endswith('%'):\n",
        "            return float(value.rstrip('%')) / 100\n",
        "    return value\n",
        "\n",
        "def json_to_text(json_obj, indent_level=0):\n",
        "    text_lines = []\n",
        "    indent_space = \"    \"  # 4 spaces for indentation\n",
        "    if isinstance(json_obj, dict):\n",
        "        for key, value in json_obj.items():\n",
        "            if value is not None:  # Ensure value is not None\n",
        "                text_lines.append(f\"{indent_space * indent_level}{key}:\")\n",
        "                text_lines.extend(json_to_text(value, indent_level + 1))\n",
        "    elif isinstance(json_obj, list):\n",
        "        for index, item in enumerate(json_obj):\n",
        "            if item is not None:  # Ensure item is not None\n",
        "                text_lines.append(f\"{indent_space * indent_level}[{index}]:\")\n",
        "                text_lines.extend(json_to_text(item, indent_level + 1))\n",
        "    else:\n",
        "        text_lines.append(f\"{indent_space * indent_level}{json_obj}\")\n",
        "\n",
        "    return text_lines\n",
        "\n",
        "\n",
        "\n",
        "def clean_dict(d):\n",
        "    if isinstance(d, dict):\n",
        "        return {k: clean_dict(v) for k, v in d.items() if clean_dict(v) not in [None, {}, []]}\n",
        "    return d\n",
        "\n",
        "def transcribe_audio(file):\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=file.name[file.name.rfind('.'):]) as tmp_file:\n",
        "        tmp_file.write(file.getvalue())\n",
        "        tmp_file_path = tmp_file.name\n",
        "\n",
        "    audio_path = tmp_file_path\n",
        "\n",
        "    # Convert MP4 to WAV if necessary\n",
        "    if file.name.lower().endswith('.mp4'):\n",
        "        video = VideoFileClip(tmp_file_path)\n",
        "        audio_path = tmp_file_path + \".wav\"\n",
        "        video.audio.write_audiofile(audio_path)\n",
        "        os.remove(tmp_file_path)\n",
        "    elif file.name.lower().endswith('.mp3'):\n",
        "        audio = AudioSegment.from_mp3(tmp_file_path)\n",
        "        audio_path = tmp_file_path + \".wav\"\n",
        "        audio.export(audio_path, format=\"wav\")\n",
        "        os.remove(tmp_file_path)\n",
        "\n",
        "    # Transcribe audio with speaker detection\n",
        "    result = model.transcribe(audio_path, verbose=True)\n",
        "\n",
        "    # Combine transcription with speaker detection\n",
        "    combined_result = []\n",
        "    current_speaker = None\n",
        "    current_text = \"\"\n",
        "\n",
        "    for segment in result[\"segments\"]:\n",
        "        if segment.get(\"speaker\") != current_speaker:\n",
        "            if current_text:\n",
        "                combined_result.append(f\"Speaker {current_speaker}: {current_text.strip()}\")\n",
        "            current_speaker = segment.get(\"speaker\", \"Unknown\")\n",
        "            current_text = segment[\"text\"]\n",
        "        else:\n",
        "            current_text += \" \" + segment[\"text\"]\n",
        "\n",
        "    # Add the last segment\n",
        "    if current_text:\n",
        "        combined_result.append(f\"Speaker {current_speaker}: {current_text.strip()}\")\n",
        "\n",
        "    # Clean up temporary files\n",
        "    os.remove(audio_path)\n",
        "\n",
        "    return \"\\n\".join(combined_result)\n",
        "\n",
        "def call_bedrock(prompt):\n",
        "    try:\n",
        "        body = json.dumps({\n",
        "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
        "            \"max_tokens\": 4096,\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            \"temperature\": 0.3,\n",
        "            \"top_p\": 0.9\n",
        "        })\n",
        "\n",
        "        modelId = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
        "        response = bedrock.invoke_model(body=body, modelId=modelId, accept='application/json', contentType='application/json')\n",
        "        response_body = json.loads(response.get('body').read())\n",
        "        return response_body['content'][0]['text']\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in call_bedrock: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def clean_transcript(input_text):\n",
        "    # Keep only lines with speaker labels (*INV:, *PAR:) and their content\n",
        "    cleaned_lines = re.findall(r'^\\*[A-Z]+:.*$', input_text, re.MULTILINE)\n",
        "    # Remove various artifacts and clean up the lines\n",
        "    cleaned_lines = [re.sub(r'\\d+_\\d+$|•\\d+_\\d+•|\\[.*?\\]|&=.*?(?:\\s|$)|&-\\w+|\\+<|\\(\\.\\.\\)|\\.\\.\\.|‡', '', line) for line in cleaned_lines]\n",
        "    # Remove leading/trailing whitespace and any remaining punctuation at the end\n",
        "    cleaned_lines = [re.sub(r'^\\s+|\\s+$|[,\\.!?]+$', '', line) for line in cleaned_lines]\n",
        "    # Remove empty lines and lines with only punctuation/spaces\n",
        "    cleaned_lines = [line for line in cleaned_lines if re.search(r'[a-zA-Z]', line)]\n",
        "    return '\\n'.join(cleaned_lines)\n",
        "\n",
        "# UI Components\n",
        "def set_page_config():\n",
        "    st.set_page_config(\n",
        "        page_title=\"LingoDx - Advanced Aphasia Analysis\",\n",
        "        page_icon=\"🧠\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\"\n",
        "    )\n",
        "\n",
        "def apply_custom_css():\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700&display=swap');\n",
        "\n",
        "body {\n",
        "    font-family: 'Poppins', sans-serif;\n",
        "    background-color: #f0f4f8;\n",
        "    color: #333;\n",
        "    line-height: 1.6;\n",
        "}\n",
        "\n",
        ".stApp {\n",
        "    background-color: #ffffff;\n",
        "    max-width: 1200px;\n",
        "    margin: 0 auto;\n",
        "    padding: 20px;\n",
        "    box-shadow: 0 0 20px rgba(0,0,0,0.1);\n",
        "}\n",
        "\n",
        "/* Header styles */\n",
        "h1 {\n",
        "    color: #2c3e50;\n",
        "    font-size: 2.5em;\n",
        "    font-weight: 700;\n",
        "    margin-bottom: 20px;\n",
        "}\n",
        "\n",
        "h2, h3 {\n",
        "    color: #34495e;\n",
        "    font-weight: 600;\n",
        "}\n",
        "\n",
        "/* Navigation bar styles */\n",
        ".stButton > button {\n",
        "    background-color: #3498db;\n",
        "    color: white;\n",
        "    border: none;\n",
        "    padding: 10px 20px;\n",
        "    font-size: 16px;\n",
        "    font-weight: 600;\n",
        "    border-radius: 5px;\n",
        "    transition: background-color 0.3s, transform 0.2s;\n",
        "}\n",
        "\n",
        ".stButton > button:hover {\n",
        "    background-color: #2980b9;\n",
        "    transform: translateY(-2px);\n",
        "}\n",
        "\n",
        "/* Content sections */\n",
        ".reportSection {\n",
        "    background-color: #ffffff;\n",
        "    border-radius: 8px;\n",
        "    padding: 25px;\n",
        "    margin-bottom: 30px;\n",
        "    box-shadow: 0 4px 6px rgba(0,0,0,0.05);\n",
        "    transition: box-shadow 0.3s;\n",
        "}\n",
        "\n",
        ".reportSection:hover {\n",
        "    box-shadow: 0 6px 12px rgba(0,0,0,0.1);\n",
        "}\n",
        "\n",
        "/* Form elements */\n",
        ".stTextInput > div > div > input,\n",
        ".stSelectbox > div > div > div {\n",
        "    background-color: #f8f9fa;\n",
        "    border: 1px solid #e0e0e0;\n",
        "    border-radius: 5px;\n",
        "    padding: 10px;\n",
        "    font-size: 16px;\n",
        "}\n",
        "\n",
        "/* Tabs styling */\n",
        ".stTabs [data-baseweb=\"tab-list\"] {\n",
        "    gap: 10px;\n",
        "    border-bottom: 2px solid #e0e0e0;\n",
        "}\n",
        "\n",
        ".stTabs [data-baseweb=\"tab\"] {\n",
        "    height: 45px;\n",
        "    padding: 10px 20px;\n",
        "    font-weight: 600;\n",
        "    background-color: #f0f4f8;\n",
        "    border-radius: 5px 5px 0 0;\n",
        "    transition: background-color 0.3s;\n",
        "}\n",
        "\n",
        ".stTabs [aria-selected=\"true\"] {\n",
        "    background-color: #3498db;\n",
        "    color: white;\n",
        "}\n",
        "\n",
        "/* Key Features list */\n",
        "ul {\n",
        "    list-style-type: none;\n",
        "    padding-left: 0;\n",
        "}\n",
        "\n",
        "ul li {\n",
        "    margin-bottom: 10px;\n",
        "    padding-left: 30px;\n",
        "    position: relative;\n",
        "}\n",
        "\n",
        "ul li::before {\n",
        "    content: '✓';\n",
        "    position: absolute;\n",
        "    left: 0;\n",
        "    color: #2ecc71;\n",
        "    font-weight: bold;\n",
        "}\n",
        "\n",
        "/* Responsive design */\n",
        "@media (max-width: 768px) {\n",
        "    .stApp {\n",
        "        padding: 10px;\n",
        "    }\n",
        "\n",
        "    h1 {\n",
        "        font-size: 2em;\n",
        "    }\n",
        "}\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "def display_home():\n",
        "    st.title(\"Welcome to LingoDx\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(\"\"\"\n",
        "        ### Our Mission\n",
        "        LingoDx is committed to revolutionizing the landscape of aphasia diagnosis and treatment.\n",
        "        We empower speech-language pathologists with cutting-edge AI technology to provide more\n",
        "        accurate, efficient, and personalized care for individuals with aphasia.\n",
        "\n",
        "        ### Key Features:\n",
        "        - 🎙️ Advanced Speech-to-Text Analysis\n",
        "        - 🧠 AI-Powered Aphasia Diagnosis\n",
        "        - 💡 Personalized Treatment Suggestions\n",
        "        - 📝 Detailed Patient Reports\n",
        "        - ❓ Intelligent Q&A System for Patients and Caregivers\n",
        "        \"\"\")\n",
        "\n",
        "    with col2:\n",
        "        pass\n",
        "    if st.button(\"Start New Analysis\"):\n",
        "        st.session_state['current_stage'] = 'upload'\n",
        "        st.rerun()\n",
        "\n",
        "def upload_data():\n",
        "    st.header(\"Upload Patient Data\")\n",
        "\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "    with col1:\n",
        "        mode = st.radio(\n",
        "            \"Select input mode:\",\n",
        "            (\"Audio Only\", \"Excel Only\", \"Audio + Excel\", \"Transcript\")\n",
        "        )\n",
        "\n",
        "        audio_file = None\n",
        "        excel_file = None\n",
        "        transcript_input = None\n",
        "\n",
        "        if mode in [\"Audio Only\", \"Audio + Excel\"]:\n",
        "            audio_file = st.file_uploader(\"Upload audio/video file for transcription\", type=['wav', 'mp3', 'mp4'])\n",
        "\n",
        "        if mode in [\"Excel Only\", \"Audio + Excel\"]:\n",
        "            excel_file = st.file_uploader(\"Upload patient data Excel file\", type=['xlsx'])\n",
        "\n",
        "        if mode == \"Transcript\":\n",
        "            transcript_input = st.file_uploader(\"Choose a file\", type=[\"txt\", \"rtf\", \"cha\"])\n",
        "\n",
        "        notes = st.text_area(\"Additional Notes\", \"Enter any additional notes here...\")\n",
        "\n",
        "    with col2:\n",
        "      pass\n",
        "\n",
        "    # Check if the required data is provided based on the selected mode\n",
        "    data_provided = False\n",
        "    if mode == \"Audio Only\" and audio_file is not None:\n",
        "        data_provided = True\n",
        "    elif mode == \"Excel Only\" and excel_file is not None:\n",
        "        data_provided = True\n",
        "    elif mode == \"Audio + Excel\" and audio_file is not None and excel_file is not None:\n",
        "        data_provided = True\n",
        "    elif mode == \"Transcript\" and transcript_input:\n",
        "        data_provided = True\n",
        "\n",
        "    if data_provided:\n",
        "        with st.spinner('Processing data...'):\n",
        "            transcription = None\n",
        "            json_data = None\n",
        "            testing_dates = None\n",
        "\n",
        "            if mode in [\"Audio Only\", \"Audio + Excel\"] and audio_file:\n",
        "                transcription = transcribe_audio(audio_file)\n",
        "                st.success(\"Audio transcribed with speaker detection successfully!\")\n",
        "\n",
        "                with st.expander(\"View Transcription\"):\n",
        "                    st.write(transcription)\n",
        "\n",
        "            if mode in [\"Excel Only\", \"Audio + Excel\"] and excel_file:\n",
        "                json_data, testing_dates = excel_to_json(excel_file)\n",
        "                if json_data is not None:\n",
        "                    st.success(\"Excel data processed successfully!\")\n",
        "\n",
        "                    with st.expander(\"View Processed Data\"):\n",
        "                        st.json(json_data)\n",
        "\n",
        "                    if testing_dates:\n",
        "                        with st.expander(\"View Testing Dates\"):\n",
        "                            for category, dates in testing_dates.items():\n",
        "                                st.write(f\"- {category}: {', '.join(dates)}\")\n",
        "                else:\n",
        "                    st.error(\"Failed to process the Excel file. Please check the file format and try again.\")\n",
        "                    return\n",
        "\n",
        "            if mode == \"Transcript\" and transcript_input:\n",
        "                content =  transcript_input.read().decode(\"utf-8\")\n",
        "                transcription = clean_transcript(content)\n",
        "\n",
        "                st.success(\"Transcript processed successfully!\")\n",
        "\n",
        "                with st.expander(\"View Cleaned Transcript\"):\n",
        "                    st.write(transcription)\n",
        "\n",
        "        # Store the processed data in session state\n",
        "        st.session_state['input_mode'] = mode\n",
        "        if transcription:\n",
        "            st.session_state['cleaned_content'] = transcription\n",
        "        if json_data:\n",
        "            st.session_state['testing_dates'] = testing_dates\n",
        "            st.session_state['cleaned_content'] = json_data\n",
        "        st.session_state['notes'] = notes\n",
        "\n",
        "        st.info(\"Data has been processed and stored. You can now proceed to the Analysis section.\")\n",
        "\n",
        "        if st.button(\"Proceed to Analysis\"):\n",
        "            st.session_state['current_stage'] = 'analysis_report'\n",
        "            st.rerun()\n",
        "    else:\n",
        "        st.warning(f\"Please provide the required {'audio file' if mode in ['Audio Only', 'Audio + Excel'] else ''}\"\n",
        "                   f\"{'Excel file' if mode in ['Excel Only', 'Audio + Excel'] else ''}\"\n",
        "                   f\"{'transcript' if mode == 'Transcript' else ''} to continue.\")\n",
        "\n",
        "def run_analysis_and_generate_report():\n",
        "    st.header(\"Analysis, Treatment, and Report\")\n",
        "    if 'input_mode' not in st.session_state:\n",
        "        st.warning(\"Please upload data first.\")\n",
        "        return\n",
        "\n",
        "    col1, col2 = st.columns([3, 1])\n",
        "    with col1:\n",
        "        mode = st.session_state['input_mode']\n",
        "        transcription = st.session_state.get('transcription', '')\n",
        "        cleaned_content = st.session_state.get('cleaned_content', {})\n",
        "        notes = st.session_state.get('notes', '')\n",
        "\n",
        "        with st.spinner(\"Analyzing patient data...\"):\n",
        "            # Analysis prompt\n",
        "            analysis_prompt = f\"\"\"\n",
        "            Analyze the following patient data for aphasia:\n",
        "\n",
        "            Input Mode: {mode}\n",
        "\n",
        "            {'Transcription: ' + transcription if transcription else ''}\n",
        "\n",
        "            {'Test Results: ' + json.dumps(cleaned_content, indent=2) if cleaned_content else ''}\n",
        "\n",
        "            Additional Notes: {notes}\n",
        "\n",
        "            Please provide a comprehensive analysis of the patient's aphasia symptoms,\n",
        "            including potential type and severity. Consider both the transcribed speech\n",
        "            and the test results in your analysis.\n",
        "\n",
        "  You are a speech pathologist, a healthcare professional who specializes in evaluating, diagnosing, and treating communication disorders, including speech, language, cognitive-communication, voice, swallowing, and fluency disorders. Your role is to help patients improve their speech and communication skills through various therapeutic techniques and exercises.\n",
        "\n",
        "  In this scenario, you will be working with a patient who has the following speech disorder or issue:\n",
        "\n",
        "  Aphasia\n",
        "  Consider the notes when diagnosing the specific type of aphasia {notes}\n",
        "\n",
        "  What is aphasia?\n",
        "  Aphasia is a disorder that results from damage to portions of the brain that are responsible for language. For most people, these areas are on the left side of the brain. Aphasia usually occurs suddenly, often following a stroke or head injury, but it may also develop slowly, as the result of a brain tumor or a progressive neurological disease. The disorder impairs the expression and understanding of language as well as reading and writing. Aphasia may co-occur with speech disorders, such as dysarthria or apraxia of speech, which also result from brain damage.\n",
        "\n",
        "  Who can acquire aphasia?\n",
        "  Most people who have aphasia are middle-aged or older, but anyone can acquire it, including young children. About 1 million people in the United States currently have aphasia, and nearly 180,000 Americans acquire it each year, according to the National Aphasia Association.\n",
        "\n",
        "  What causes aphasia?\n",
        "  Aphasia is caused by damage to one or more of the language areas of the brain. Most often, the cause of the brain injury is a stroke. A stroke occurs when a blood clot or a leaking or burst vessel cuts off blood flow to part of the brain. Brain cells die when they do not receive their normal supply of blood, which carries oxygen and important nutrients. Other causes of brain injury are severe blows to the head, brain tumors, gunshot wounds, brain infections, and progressive neurological disorders, such as Alzheimer's disease.\n",
        "\n",
        "  Based on the test scores that I give you, determine the type of aphasia:\n",
        "  Here is what each test score means:\n",
        "\n",
        "  {wab}\n",
        "  {bnt}\n",
        "  {palpa}\n",
        "\n",
        "  Determine the following based on the test scores.\n",
        "\n",
        "  1. Fluency vs. Non-fluency\n",
        "    - Fluent: Wernicke's, Conduction, Anomic, Transcortical Sensory\n",
        "    - Non-fluent: Broca's, Global, Transcortical Motor\n",
        "\n",
        "  2. Comprehension\n",
        "    - Good: Broca's, Conduction, Anomic, Transcortical Motor\n",
        "    - Poor: Wernicke's, Global, Transcortical Sensory\n",
        "\n",
        "  3. Repetition\n",
        "    - Impaired: Broca's, Wernicke's, Conduction, Global\n",
        "    - Preserved: Anomic, Transcortical Sensory, Transcortical Motor\n",
        "\n",
        "  4. Naming\n",
        "    - Severely Impaired: Wernicke's, Global, Anomic\n",
        "    - Moderately Impaired: Broca's, Conduction, Transcortical types\n",
        "\n",
        "  Use the factors above to determine the aphasia. Make sure that you show your wok and tell me which one you picked and why\n",
        "  I want you to grade through the factors above and output that.\n",
        "\n",
        "  Here are the patients test scores:\n",
        "  {cleaned_content}\n",
        "\n",
        "  If speech samples are provided, feel free to use that in the diagnosis as well.\n",
        "\n",
        "  Based on the information provided, please do the following:\n",
        "  {information}\n",
        "  Do this using {answer_info} provided.\n",
        "  By implementing these improvements, Document 2 could become even more informative and useful for patients, providing a comprehensive, understandable, and actionable report of their condition and treatment plan.\n",
        "      \"\"\"\n",
        "\n",
        "            analysis_response = call_bedrock(analysis_prompt)\n",
        "\n",
        "            # Treatment prompt\n",
        "            treatment_prompt = f\"\"\"\n",
        "          Based on the following aphasia analysis and patient data,\n",
        "          suggest a comprehensive treatment plan:\n",
        "\n",
        "          Analysis: {analysis_response}\n",
        "\n",
        "          Patient Data: {json.dumps(cleaned_content, indent=2)}\n",
        "\n",
        "          Additional Notes: {notes}\n",
        "\n",
        "          Please provide detailed treatment suggestions, including specific\n",
        "          exercises, therapy techniques, and goals for the patient.\n",
        "\n",
        "  1. Non-fluent speech:\n",
        "    - Melodic Intonation Therapy (MIT) {mit}\n",
        "    - Utterance-based therapy {utterances}\n",
        "\n",
        "  2. Word retrieval issues:\n",
        "    - Techniques from Anomia therapy {anomia}\n",
        "    - Strategies from Intro to Aphasia Therapy {intro}\n",
        "\n",
        "  3. Grammatical errors:\n",
        "    - Agrammatism therapy {agrammatism}\n",
        "    - Techniques from Utterance-based therapy\n",
        "\n",
        "  4. Repetitions and revisions:\n",
        "    - Strategies from Preservation therapy {preservation}\n",
        "    - Techniques from Anomia therapy\n",
        "\n",
        "  5. Paraphasias:\n",
        "    - Relevant techniques from Wernicke's Aphasia therapy {wernicke}\n",
        "    - Strategies from Anomia therapy\n",
        "\n",
        "  6. Neologisms:\n",
        "    - Approaches from Wernicke's Aphasia therapy\n",
        "    - Techniques from Intro to Aphasia Therapy\n",
        "\n",
        "  7. Perseveration:\n",
        "    - Strategies from Preservation therapy {preservation}\n",
        "    - Techniques from Intro to Aphasia Therapy {intro}\n",
        "\n",
        "  8. Comprehension issues:\n",
        "    - Auditory Comprehension therapy\n",
        "    - Techniques from Wernicke's Aphasia therapy\n",
        "\n",
        "  Be creative. There are hundreds of ways to treat each and every symptom. Use the miscellaneous therapies as well. {misc}\n",
        "\n",
        "  For each suggested therapy, provide:\n",
        "  - Brief description of the therapy\n",
        "  - How it specifically addresses the patient's symptom\n",
        "  - Expected benefits based on the patient's presentation\n",
        "\n",
        "\n",
        "  emember the even if there are a couple errors here or there, it can still be that type of aphasia.\n",
        "\n",
        "  Ensure suggestions are tailored to the patient's specific symptoms and severity. Use the Intro to Aphasia Therapy {intro} for general principles and approaches that might apply across different symptoms.\n",
        "\n",
        "  When suggesting therapies, consider:\n",
        "  1. The patient's specific type of aphasia\n",
        "  2. The severity of their symptoms (based on WAB score and symptom analysis)\n",
        "  3. Any notable strengths that could be leveraged in therapy\n",
        "  4. Potential for combining techniques from different manuals for a comprehensive approach\n",
        "\n",
        "  Format it like this:\n",
        "\n",
        "  1. Comprehension Issues:\n",
        "  Therapy: Auditory Comprehension Therapy Description: This therapy focuses on improving the patient's ability to understand spoken language through structured exercises that gradually increase in complexity.\n",
        "  How it addresses the symptom: B.B.'s comprehension score (125/200) indicates significant difficulty in understanding spoken language, which is characteristic of Wernicke's Aphasia.\n",
        "  Expected benefits: Improved ability to understand spoken language in daily life, which can enhance overall communication and reduce frustration.\n",
        "  Specific approach:\n",
        "  Start with simple yes/no questions about familiar topics\n",
        "  Progress to following one-step commands, then multi-step commands Use visual aids to support comprehension\n",
        "  Gradually introduce more complex language and abstract concepts\n",
        "  2. Word Retrieval Issues:\n",
        "  Therapy: Semantic Feature Analysis (from Anomia Therapy) Description: This technique involves analyzing the features of objects or concepts to strengthen semantic networks and improve word retrieval.\n",
        "  How it addresses the symptom: B.B.'s naming score (58/100) suggests moderate difficulty in word retrieval, which is common in Wernicke's Aphasia.\n",
        "  Expected benefits: Improved ability to access and produce target words, potentially reducing the occurrence of paraphasias and enhancing overall expressive language.\n",
        "  Specific approach:\n",
        "  Present a target word (e.g., \"dog\")\n",
        "  Guide B.B. to generate related semantic features (e.g., \"has fur\", \"barks\", \"is a pet\") Use these features as cues for word retrieval in future sessions\n",
        "  Gradually increase the complexity of target words\n",
        "  3. Paraphasias and Neologisms:\n",
        "  Therapy: Phonological Component Analysis (adapted from Wernicke's Aphasia Therapy) Description: This approach focuses on the sound structure of words to improve word production accuracy.\n",
        "  How it addresses the symptom: Paraphasias and neologisms are common in Wernicke's Aphasia, and B.B.'s moderate naming difficulties suggest these may be present.\n",
        "  Expected benefits: Reduced occurrence of paraphasias and neologisms, leading to more accurate and effective verbal communication.\n",
        "  Specific approach:\n",
        "  Present a target word and analyze its phonological components (number of syllables, initial sound, rhyming words)\n",
        "  Practice producing words with similar phonological structures\n",
        "  Use minimal pair exercises to distinguish between similar-sounding words\n",
        "  Incorporate self-monitoring techniques to help B.B. recognize and correct errors 4. Repetition Difficulties:\n",
        "  Therapy: Repetition Therapy (from Utterance-based Therapy) Description: This therapy involves structured repetition exercises that gradually increase in complexity.\n",
        "  How it addresses the symptom: B.B.'s repetition score (52/100) indicates significant difficulty in this area, which is common in Wernicke's Aphasia.\n",
        "  Expected benefits: Improved ability to repeat words and phrases accurately, which can support overall language production and comprehension.\n",
        "  Specific approach:\n",
        "  Start with single words, progressing to short phrases and sentences Use visual and written cues to support repetition\n",
        "  Incorporate rhythmic and melodic elements to facilitate repetition (drawing from Melodic Intonation Therapy)\n",
        "  Gradually reduce cues as B.B.'s performance improves\n",
        "  5. Overall Language Use:\n",
        "  Therapy: Conversational Coaching (from Intro to Aphasia Therapy) Description: This approach focuses on improving functional communication in everyday situations.\n",
        "  How it addresses the symptom: While not addressing a specific symptom, this therapy can help B.B. integrate skills learned in other therapies into real-life communication.\n",
        "  Expected benefits: Improved ability to communicate effectively in daily life, increased confidence, and better social interaction.\n",
        "  Specific approach:\n",
        "  Practice common conversational scenarios (e.g., ordering at a restaurant, talking to a neighbor) Teach and practice communication repair strategies\n",
        "  Incorporate multimodal communication (gestures, writing, drawing) to support verbal communication\n",
        "  Gradually increase the complexity and length of conversational exchanges\n",
        "\n",
        "  These therapies should be implemented in a structured program, with regular reassessment to track progress and adjust the treatment plan as needed. The focus should be on functional communication and improving B.B.'s ability to participate in daily activities and social interactions.\n",
        "\n",
        "  Provide a rationale for each therapy choice, explaining why it's particularly suited to this patient's needs based on their specific presentation of aphasia.\n",
        "  When generating responses, consider the patient's current level of ability and gradually increase the complexity of tasks. Provide positive reinforcement and corrective feedback as needed.\"\"\"\n",
        "\n",
        "            treatment_response = call_bedrock(treatment_prompt)\n",
        "\n",
        "            # Report prompt\n",
        "            report_prompt = f\"\"\"\n",
        "          Using the analysis: {analysis_response} and the treatment suggestions: {treatment_response}, write a medical report about the patient\n",
        "\n",
        "          Here is the original data: {st.session_state['cleaned_content']}\n",
        "          Use the original content for citations for why you wrote what you wrote.\n",
        "\n",
        "           Name:\n",
        "Date of Birth: 03/15/1952 Age: 52\n",
        "Background Information\n",
        "Date of CVA: 11/7/2004 Handedness: Right\n",
        "Clinician:\n",
        "University of Texas at Austin\n",
        "Aphasia Research Laboratory Department of Communications Sciences & Disorders Evaluation Report\n",
        " XX is a 52 year old, right-handed male who lives in Austin with his wife. He has three sons, all of whom no longer live at his residence. He is self-employed and operates his own plumbing business. Mr. XX suffered a left hemisphere cerebral vascular accident on November 7, 2004. He was hospitalized for approximately six days and thereafter, re- ceived outpatient speech therapy for a period of 2 weeks that focused on repetition, nam- ing, word-finding, and writing to dictation. Mr. XX reports continued verbal expression difficulties, including word finding and paraphasias, as well as writing abilities similar to his verbal expression. He also reports no problems with auditory comprehension, gestur- al expression or reading. Mr. XX came to the evaluation to see if further treatment was recommended.\n",
        "Medical History\n",
        "As previously mentioned, Mr. XX experienced a stroke in the left frontal parietal region on November 7, 2004. An MRI strongly suggested an embolism, although no source was found. Mr. XX’s Factor V Leiden heterozygous state was believed to be the precipitating factor in his embolic stroke. His vessels were normal and he had no other risk factors other than obesity and moderate hyperlipidemia. He had extremely high cholesterol and triglycerides, which have since returned to normal with the maintenance of a low fat, low cholesterol diet and Lipitor therapy (10mg at bedtime). Medical examination on January 4, 2005 revealed mild expressive aphasia, intact reading abilities, excellent dexterity, sub- tle right-side dysdiadochokinesis, no dysmetria or dyssynergia, symmetrical reflexes, and a regular heart rhythm. Mr. XX currently takes 325mg of aspirin and Lipitor daily.\n",
        "Behavior During Evaluation\n",
        "Mr. XX came in for the evaluation a total of four times, including three sessions for two hours each, as well as one final session for 1.25 hours. He was pleasant and cooperative and performed all tests administered. Mr. XX did not display evidence of fatigue or anx- iety throughout the testing.\n",
        "Tests Administered (See attachment for references)\n",
        "Western Aphasia Battery, WAB (Kertesz, A., 1982)\n",
        "\n",
        " - Intended purpose of the WAB is to evaluate several aspects of language con- tent, fluency, auditory comprehension, repetition and naming, reading, writ- ing, and praxis.\n",
        "Boston Naming Test, BNT (Kaplan, E., Goodglass, H., & Weintraub, S., 2001)\n",
        "- Intended purpose of the BNT is to evaluate picture naming responses and\n",
        "categorize the type of errors made.\n",
        "Psycholinguistic Assessments of Language Processing in Aphasia, PALPA\n",
        "(Kay, J., Lesser, M., & Coltheart, 1992)\n",
        "- Intended purpose is to evaluate language processing skills in individuals with\n",
        "aphasia. Sections of the test appropriate for this assessment were used. The Pyramids and Palm Trees Test, PPT (Howard, D. & Patterson, K., 1992)\n",
        "- Intended purpose is to assess an individual’s ability to access detailed seman- tic representations from words and pictures.\n",
        "Dynamic Assessment\n",
        "- To evaluate Mr. XX’s functional ability to write names, addresses, and tele- phone numbers to dictation as it pertains to his occupation.\n",
        "Summary of Evaluation Results (See attachment for scores)\n",
        "Fluency\n",
        "A language sample was obtained to evaluate Mr. XX’s ability to fluently relay his thoughts when retelling a familiar wordless picture book story, Cinderella. Mr. XX’s speech was characterized by frequent phonemic paraphasias (distorting a word by substi- tuting, omitting, or adding phonemic elements) when telling the story. For example, he said “Cindereda,” “Cinderlessa” and “Cinderessa” for the word “Cinderella.” He was able to self-correct his phonemic paraphasias on most occasions. Mr. XX’s speech was also characterized by pauses and filler words such as “uh” while accessing words.\n",
        "Mr. XX’s fluency was also evaluated on a subtest of the WAB. The spontaneous speech subtest is designed to elicit conversational speech in reply to questions asked in the con- text of an interview and a picture description. He scored 19 out of 20 possible points on the subtest. His account of the picture consisted of naming the people, objects, and ac- tions and describing their interactions with ample detail. Mr. XX demonstrated moderate use of phonemic paraphasias during this task, including mostly complete, relevant, and grammatical sentences of high complexity and only occasional hesitations. He received a fluency score of 9 out of 10 possible points.\n",
        "Comprehension\n",
        "Mr. XX’s auditory word comprehension was intact for yes/no questions (60/60) and audi- tory word recognition (60/60) on the WAB, as well as relatively intact for sequential\n",
        "\n",
        " commands (75/80). Mr. XX’s ability to discriminate between non-word (67/72) and real word (67/70) minimal pairs was relatively intact on the subtests of the PALPA. The audi- tory lexical decision task on the PALPA for both words (57/60) and non-words (56/60), as well as discriminating between words based on morphology (56/60), were of minimal difficulty for Mr. XX. In the latter task, morphological endings were added to words to transform them into non-words. The auditory lexical decision task examined Mr.’s XX’s ability to identify real words versus nonwords. In addition, he had no difficulty with the spoken word picture matching section (40/40) or the written word picture matching sec- tion (40/40) of the PALPA. These subtests assessed Mr. XX’s semantic comprehension abilities by requiring him to identify the picture that correctly matched the written or spo- ken word from among several distracter items. Throughout the session, Mr. XX dis- played understanding of task directions and rarely asked the clinician to repeat the direc- tions throughout various tasks.\n",
        "Naming\n",
        "On the Boston Naming Test, Mr. XX had minimal difficulty spontaneously naming (58/60) the pictures, although phonological paraphasias were frequently noted during the assessment. For example, Mr. XX said “beaber” for “beaver” and “tripot” for “tripod.” He was able to self-correct his phonemic paraphasias on all occasions. Mr. XX produced the correct response following a stimulus cue on five occasions, often indicating that he al- ready knew the function of each object. On two occasions, phonemic cues were provided to aid response accuracy. Mr. XX scored above the mean for individuals in the same age group.\n",
        "On the WAB, Mr. XX’s object naming (60/60), sentence completion (10/10), and respon- sive speech (9/10) were relatively intact. He did not demonstrate any difficulty in these areas. Mr. XX did, however, demonstrate difficulty with word fluency, which was as- sessed by his ability to name as many animals as possible in the time limit of one minute (12/20). Additionally, he had no difficulty naming letters (52/52), yet demonstrated some trouble producing sounds made by various letters (42/52) on the PALPA.\n",
        "Semantic Processing\n",
        "Mr. XX’s semantic processing abilities, or abilities to retrieve complete and correct se- mantic information, were relatively intact as determined by all three subtests of the Pyramids and Palm Trees Test. The test consists of triads of items, in which one item, given at the top, must be matched with one of two others. The two choices are semanti- cally related, whereas the item at the top is usually from a different category. The choice is then made on the basis of a semantic property or association shared by the given item and the target item. Three subtests were administered. Mr. XX had relatively consistent accuracy on all subtests, scoring 49 out of 52 on the three written words subtest, 49 out of 52 on the 1 written word, two pictures subtest, and 51 out of 52 on the three pictures sub- test.\n",
        "\n",
        " Mr. XX’s semantic comprehension abilities were also shown to be relatively intact by subtests of the PALPA. He had no difficulty listening to spoken words and pointing to the matching picture (40/40) or reading words and identifying the matching picture (40/40). He also experienced minimal difficulty with the Auditory Synonym Judgments subtest (57/60) or the Written Synonyms Judgments subtest (59/60) of the PALPA. The former subtest assessed Mr. XX’s ability to judge whether two spoken words are close in mean- ing, whereas the latter subtest assessed his ability to determine whether two written words are close in meaning.\n",
        "Reading\n",
        "Overall, his various reading skills were relatively intact. The reading comprehension of sentences subtest (40/40) and reading commands subtest (18.5/20) of the WAB demon- strated that Mr. XX’s abilities in these areas were relatively preserved. On subtests of the PALPA, he exhibited relatively intact skills in reading one (7/8), two (8/8) and three (8/8) syllable words, as well as three (6/6), four (6/6), five (6/6), and six (6/6) letter words. Mr. XX demonstrated great difficulty on the task involving reading non-words of 3, 4, 5, and 6 letters, scoring 10 out of 24 possible points. He had numerous phonemic paraphasias when reading the words aloud and experienced more difficulty as the words increased in length. On the “three written words” subtest (49/52) of the PPT, he displayed a relatively intact ability to select semantically related words upon reading three written choices.\n",
        "Writing\n",
        "Overall Mr. XX demonstrated relatively intact writing skills. On the subtests of the WAB, Mr. XX demonstrated relatively preserved skills in writing on request (6/6) and writing to dictation (7.5/10). His written output describing a picture was grammatically and seman- tically appropriate. However, his score (20.5/34) reflected his slowed rate of written pro- duction, making it difficult to complete the task in the amount of time allotted.\n",
        "Because Mr. XX’s occupation often requires him to take phone orders and record names, addresses, and telephone numbers, this functional ability was assessed. Mr. XX’s ability\n",
        "to write notes to dictation was also evaluated through dynamic assessment procedures. He participated in two simulated telephone conversations with the examiner, one in which information was presented at a fast rate, and another in which information was presented more slowly. During the task, Mr. XX spontaneously applied many strategies that helped facilitate accurate transcription of information. For example, during the first trial, Mr. XX indicated to his communication partner that information was being con- veyed too quickly. He asked for multiple repetitions of the data when necessary and in- formed his listener when he was ready to receive additional information. Mr. XX indi- cated that he had worked on these strategies in previous therapy. In addition to the strategies mentioned above, it was also recommended that he repeat information back to his communication partner in order to confirm accurate spelling and recording of infor-\n",
        "\n",
        " mation. Although Mr. XX’s ability to write to dictation appeared relatively intact, it was recommended that he continue to use his strategies when taking messages in order to fa- cilitate accurate transcription.\n",
        "Spelling\n",
        "On the PALPA, Mr. XX demonstrated great difficulty spelling nonwords, scoring 5 out of 24 possible points. He demonstrated nearly equal difficulty spelling both regular words such as wind (15/20), as well as spelling irregular words such as giraffe (14/20). Howev- er, he had minimal difficulty spelling picture names to dictation (36/40) and writing pic- ture names (36/40). He reported that he experienced pre-morbid spelling difficulties.\n",
        "Repetition\n",
        "Mr. XX demonstrated relatively intact ability to repeat words as evidenced on the PALPA (40/40). However, difficulty was demonstrated when repeating words, phrases, and sen- tences on the WAB (82/100), as well as when repeating non-words on the PALPA (26/30).\n",
        "Apraxia Battery\n",
        "The apraxia subtest of the WAB evaluated Mr. XX’s ability to complete skilled or prac- ticed movements that involve the upper limbs (i.e., make a fist) and/or face (i.e., close your eyes) and sometimes require instrumental (i.e., use a comb) or complex (i.e., pretend to drive a car) actions. Mr. XX had no difficulty with these tasks and scored 60 out of 60 possible points.\n",
        "Clinical Impressions\n",
        "According to the results of the WAB, Mr. XX displays characteristics of anomic aphasia. He presented with relatively fluent speech marked by a primary deficit of frequent pho- nemic paraphasias. Mr. XX demonstrated difficulty repeating non-words, phrases, and sentences, as they also included numerous phonemic paraphasias. Additionally, he dis- played a phonological processing deficit given impaired performance with spelling, re- peating, reading, and writing non-words across all tests. No other significant deficits were noted in reading, writing, or visual lexical decision making. Mr. XX also demon- strated relatively intact comprehension skills, intact semantic processing skills, and no significant naming deficits. Additional strengths include his ability to self-cue and self- correct phonemic paraphasias in order to reduce the errors in his speech, as well as his tendency to use strategies that facilitate accurate dictation (i.e., asking for multiple repeti- tions of information).\n",
        "Recommendations:\n",
        "Given Mr. XX’s high-level communication skills, he does not qualify for experimental treatment in the aphasia lab at this time. It is recommended that he continue to facilitate effective communication by using strategies such as asking for multiple repetitions of in- formation when necessary, slowing his rate of speech, indicating when he is ready to re-\n",
        "\n",
        " ceive information when writing to dictation and repeating information back to his listener in order to confirm accurate dictation. He and his wife were provided with information regarding the evaluation.\n",
        "\n",
        "\n",
        "          Make this something a patient can use. It has to be friendly, and reassuring. It has to take their considerations into play as listed here {notes}.\n",
        "\n",
        "          Follow the example in the example report: {example_report}\n",
        "          Make the report look like this(this patient is not the one you shoud follow: {example_report}\n",
        "\n",
        "          You cannot be unsure about what you are telling them. Write everything in long full paragraphs.\n",
        "\n",
        "          The report should include the following sections:\n",
        "          Patient Information (only include if available)\n",
        "          Background Information (only include if available)\n",
        "          Medical History (only include if available)\n",
        "          Behavior During Evaluation (only include if available)\n",
        "          Tests Administered\n",
        "          Summary of Evaluation Results (Write it all in full length paragraphs)\n",
        "          - Fluency (2 short paragraphs)\n",
        "          - Comprehension (2 short paragraphs)\n",
        "          - Naming (2 short paragraphs)\n",
        "          - Semantic Processing (2 short paragraphs)\n",
        "          - Reading (1 paragraph)\n",
        "          - Writing (1 paragraph)\n",
        "          - Spelling (1 paragraph)\n",
        "          - Repetition (1 paragraph)\n",
        "          - Apraxia Battery (1 paragraph)\n",
        "\n",
        "          Take the patient notes into consideration: {notes}\n",
        "\n",
        "          Give me a report for this patient based on the information I have given you. If there is anything you don't know, don't add it. Make this report as comprehensive and long as possible. Write what each of the scores mean in the tests in your analysis of results section.\n",
        "          \"\"\"\n",
        "            report_response = call_bedrock(report_prompt)\n",
        "\n",
        "        st.subheader(\"Comprehensive Patient Report\")\n",
        "        st.write(report_response + treatment_response)\n",
        "        st.session_state['report_response'] = report_response\n",
        "\n",
        "        # Download button for the report\n",
        "        report_text = report_response.encode()\n",
        "        b64 = base64.b64encode(report_text).decode()\n",
        "        href = f'<a href=\"data:file/txt;base64,{b64}\" download=\"patient_report.txt\">Download Report</a>'\n",
        "        st.markdown(href, unsafe_allow_html=True)\n",
        "\n",
        "    with col2:\n",
        "        lottie_url = \"https://assets3.lottiefiles.com/packages/lf20_q5pk6p1k.json\"\n",
        "        lottie_json = load_lottie_url(lottie_url)\n",
        "        st_lottie(lottie_json, height=300)\n",
        "\n",
        "def run_qa():\n",
        "    st.header(\"Q&A System\")\n",
        "\n",
        "    if 'report_response' not in st.session_state:\n",
        "        st.warning(\"Please generate a patient report first.\")\n",
        "        return\n",
        "\n",
        "    question = st.text_input(\"Ask a question about the patient, aphasia, or suggested therapies:\")\n",
        "\n",
        "    if question:\n",
        "        with st.spinner(\"Generating answer...\"):\n",
        "            context = f\"\"\"\n",
        "            Patient Report: {st.session_state['report_response']}\n",
        "            \"\"\"\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            Based on the following context information,\n",
        "            please answer the following question:\n",
        "\n",
        "            Context:\n",
        "            {context}\n",
        "\n",
        "            Question: {question}\n",
        "\n",
        "            Please provide a comprehensive and informative answer.\n",
        "            \"\"\"\n",
        "\n",
        "            response = call_bedrock(prompt)\n",
        "\n",
        "        st.subheader(\"Answer\")\n",
        "        st.write(response)\n",
        "\n",
        "        # Save Q&A\n",
        "        if 'qa_history' not in st.session_state:\n",
        "            st.session_state['qa_history'] = []\n",
        "        st.session_state['qa_history'].append((question, response))\n",
        "        st.success(\"Q&A saved successfully!\")\n",
        "\n",
        "    # Display Q&A history\n",
        "    if 'qa_history' in st.session_state and st.session_state['qa_history']:\n",
        "        st.subheader(\"Q&A History\")\n",
        "        for i, (q, a) in enumerate(st.session_state['qa_history'], 1):\n",
        "            with st.expander(f\"Q&A {i}: {q[:50]}...\"):\n",
        "                st.write(f\"Q: {q}\")\n",
        "                st.write(f\"A: {a}\")\n",
        "\n",
        "def display_qa_resources():\n",
        "    st.header(\"Q&A and Resources\")\n",
        "\n",
        "    tab1, tab2 = st.tabs([\"Q&A System\", \"Resource Center\"])\n",
        "\n",
        "    with tab1:\n",
        "        run_qa()\n",
        "\n",
        "    with tab2:\n",
        "        resource_center()\n",
        "\n",
        "def resource_center():\n",
        "    st.header(\"Resource Center\")\n",
        "\n",
        "    col1, col2 = st.columns([3, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.write(\"\"\"\n",
        "        Welcome to the LingoDx Resource Center. Here you'll find valuable information\n",
        "        and resources for both patients and caregivers dealing with aphasia.\n",
        "        \"\"\")\n",
        "\n",
        "        col_a, col_b = st.columns(2)\n",
        "\n",
        "        with col_a:\n",
        "            st.subheader(\"For Patients\")\n",
        "            st.markdown(\"\"\"\n",
        "            - [Aphasia Recovery Connection](https://www.aphasiarecoveryconnection.org/)\n",
        "            - [National Aphasia Association](https://www.aphasia.org/)\n",
        "            - [Aphasia Hope Foundation](https://www.aphasiahope.org/)\n",
        "            - [Tactus Therapy Apps](https://tactustherapy.com/apps/)\n",
        "            \"\"\")\n",
        "\n",
        "        with col_b:\n",
        "            st.subheader(\"For Caregivers\")\n",
        "            st.markdown(\"\"\"\n",
        "            - [ASHA Aphasia Caregiver Guide](https://www.asha.org/public/speech/disorders/aphasia-caregiver-guide/)\n",
        "            - [Aphasia Center of California](https://www.aphasiacenter.org/resources-for-caregivers/)\n",
        "            - [Lingraphica - Aphasia Caregiver Guide](https://www.aphasia.com/aphasia-resource-library/aphasia-caregivers-guide/)\n",
        "            - [Caregiver Action Network](https://caregiveraction.org/)\n",
        "            \"\"\")\n",
        "\n",
        "        st.subheader(\"Educational Videos\")\n",
        "        video_col1, video_col2 = st.columns(2)\n",
        "        with video_col1:\n",
        "            st.video(\"https://www.youtube.com/watch?v=zjkgSCIXo3k\")\n",
        "        with video_col2:\n",
        "            st.video(\"https://www.youtube.com/watch?v=CqmW9cYZNZs\")\n",
        "\n",
        "    with col2:\n",
        "        lottie_url = \"https://assets9.lottiefiles.com/packages/lf20_kdx6cani.json\"\n",
        "        lottie_json = load_lottie_url(lottie_url)\n",
        "        st_lottie(lottie_json, height=300)\n",
        "\n",
        "\n",
        "def adaptive_resources():\n",
        "    st.subheader(\"Personalized Resources\")\n",
        "\n",
        "    if 'report_response' not in st.session_state:\n",
        "        st.warning(\"Please complete the analysis and generate a report first.\")\n",
        "        return\n",
        "\n",
        "    # Extract key information from the report\n",
        "    analysis_prompt = f\"\"\"\n",
        "    Based on the following patient report, please extract and summarize the following information:\n",
        "    1. Type of aphasia\n",
        "    2. Severity (mild, moderate, severe)\n",
        "    3. Key symptoms (list up to 5)\n",
        "    4. Main areas for improvement (list up to 3)\n",
        "\n",
        "    Patient Report:\n",
        "    {st.session_state['report_response']}\n",
        "\n",
        "    Please provide the information in a simple list format.\n",
        "    \"\"\"\n",
        "\n",
        "    analysis_response = call_bedrock(analysis_prompt)\n",
        "\n",
        "    st.write(\"Patient Information:\")\n",
        "    st.write(analysis_response)\n",
        "\n",
        "    # Generate personalized resources\n",
        "    resources_prompt = f\"\"\"\n",
        "    Based on the following patient information:\n",
        "    {analysis_response}\n",
        "\n",
        "    Please suggest personalized resources for each of the following categories:\n",
        "    1. Mobile Apps\n",
        "    (2-3 suggestions)\n",
        "    2. Websites\n",
        "    (2-3 suggestions)\n",
        "    3. Home Exercises\n",
        "    (2-3 suggestions)\n",
        "    4. Communication Techniques\n",
        "    (2-3 suggestions)\n",
        "    5. Caregiver Resources\n",
        "    (2-3 suggestions)\n",
        "\n",
        "    For each resource, provide:\n",
        "    - Name\n",
        "    - A link to the resource\n",
        "    - Brief description (1-2 sentences)\n",
        "    - Why it's particularly helpful for this patient\n",
        "\n",
        "    Please format each category as a section with bullet points for each resource.\n",
        "    \"\"\"\n",
        "\n",
        "    resources_response = call_bedrock(resources_prompt)\n",
        "\n",
        "    st.subheader(\"Personalized Resources\")\n",
        "    st.write(resources_response)\n",
        "\n",
        "    # Additional personalized content\n",
        "    st.subheader(\"Daily Communication Tips\")\n",
        "    tips_prompt = f\"\"\"\n",
        "    Based on the patient information provided earlier:\n",
        "    {analysis_response}\n",
        "\n",
        "    Provide 5 practical daily communication tips for the patient and their caregivers.\n",
        "    These tips should be specific to the patient's symptoms and areas for improvement.\n",
        "\n",
        "    Format each tip as a bullet point.\n",
        "    \"\"\"\n",
        "    tips_response = call_bedrock(tips_prompt)\n",
        "    st.write(tips_response)\n",
        "\n",
        "\n",
        "def display_qa_resources():\n",
        "    st.header(\"Q&A and Resources\")\n",
        "\n",
        "    tab1, tab2, tab3 = st.tabs([\"Q&A System\", \"Adaptive Resources\", \"General Resource Center\"])\n",
        "\n",
        "    with tab1:\n",
        "        run_qa()\n",
        "\n",
        "    with tab2:\n",
        "        adaptive_resources()\n",
        "\n",
        "    with tab3:\n",
        "        resource_center()\n",
        "\n",
        "def main():\n",
        "    set_page_config()\n",
        "    apply_custom_css()\n",
        "\n",
        "    # Initialize session state\n",
        "    if 'current_stage' not in st.session_state:\n",
        "        st.session_state['current_stage'] = 'home'\n",
        "\n",
        "    if 'cleaned_content' not in st.session_state:\n",
        "        st.session_state['cleaned_content'] = {}\n",
        "\n",
        "    # Top navigation bar using Streamlit components\n",
        "    col1, col2, col3, col4, col5 = st.columns(5)\n",
        "\n",
        "    with col1:\n",
        "        if st.button(\"Home\"):\n",
        "            st.session_state['current_stage'] = 'home'\n",
        "            st.rerun()\n",
        "    with col2:\n",
        "      pass\n",
        "\n",
        "    with col3:\n",
        "        if st.button(\"Upload Data\"):\n",
        "            st.session_state['current_stage'] = 'upload'\n",
        "            st.rerun()\n",
        "\n",
        "    with col4:\n",
        "        if st.button(\"Analysis & Report\"):\n",
        "            st.session_state['current_stage'] = 'analysis_report'\n",
        "            st.rerun()\n",
        "\n",
        "    with col5:\n",
        "        if st.button(\"Q&A / Resources\"):\n",
        "            st.session_state['current_stage'] = 'qa_resources'\n",
        "            st.rerun()\n",
        "\n",
        "    # Main content\n",
        "    if st.session_state['current_stage'] == 'home':\n",
        "        display_home()\n",
        "    elif st.session_state['current_stage'] == 'upload':\n",
        "        upload_data()\n",
        "    elif st.session_state['current_stage'] == 'analysis_report':\n",
        "        run_analysis_and_generate_report()\n",
        "    elif st.session_state['current_stage'] == 'qa_resources':\n",
        "        display_qa_resources()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "B4FLWIuYhVKR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "e398f5d8-a48b-4ec3-d2d5-371a21c30c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AWS_ACCESS_KEY' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c253d4b3cc70>\u001b[0m in \u001b[0;36m<cell line: 581>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;31m# Initialize AWS clients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m s3 = boto3.client('s3',\n\u001b[0;32m--> 582\u001b[0;31m                   \u001b[0maws_access_key_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAWS_ACCESS_KEY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m                   \u001b[0maws_secret_access_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAWS_SECRET_KEY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                   region_name=AWS_REGION)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AWS_ACCESS_KEY' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz0YmkSFG1RIOAHx0q1qGz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
