{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPd5RG3qIEbn"
      },
      "source": [
        "#**Main Application**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZYWetAj5m1T",
        "outputId": "09d3936f-e589-4c4a-ed60-7aa6862bb5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.0)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, tenacity, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.38.0 tenacity-8.5.0 watchdog-4.0.2\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.35.13-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.13 (from boto3)\n",
            "  Downloading botocore-1.35.13-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.13->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.13->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.13->boto3) (1.16.0)\n",
            "Downloading boto3-1.35.13-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.13-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.35.13 botocore-1.35.13 jmespath-1.0.1 s3transfer-0.10.2\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Collecting doc2docx\n",
            "  Downloading doc2docx-0.2.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting PyMuPDFb==1.24.10 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from doc2docx) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading doc2docx-0.2.4-py3-none-any.whl (6.8 kB)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: python-docx, pyngrok, PyMuPDFb, doc2docx, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.10 PyMuPDFb-1.24.10 doc2docx-0.2.4 pyngrok-7.2.0 python-docx-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install --upgrade boto3\n",
        "!pip install PyMuPDF python-docx pandas openpyxl doc2docx pyngrok\n",
        "access_key = \"Insert Key Here\"\n",
        "access_secret = \"Insert Secret Here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT1RVavm5l0d",
        "outputId": "53eb51c6-cdfc-45a6-c60a-6a6dafb0b699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.171.16.37\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEb76dDD5o2e",
        "outputId": "ecb83ce0-22a8-4f07-e97a-2bc51e7ab493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Streamlit app is running on: NgrokTunnel: \"https://7012-34-148-200-43.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Set your ngrok authtoken here\n",
        "NGROK_AUTH_TOKEN = \"Insert AuthToken Here\"\n",
        "\n",
        "def run_streamlit_with_ngrok():\n",
        "    # Set ngrok authtoken\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "    # Start ngrok tunnel\n",
        "    try:\n",
        "        public_url = ngrok.connect(addr=\"8501\", proto=\"http\", name=\"streamlit\")\n",
        "        print(f\"Streamlit app is running on: {public_url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up ngrok: {e}\")\n",
        "        return\n",
        "\n",
        "    # Run Streamlit app\n",
        "    os.system(\"streamlit run main.py &\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_streamlit_with_ngrok()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "I1AxVsWD1RQz",
        "outputId": "fd40f6c3-6175-4ecf-d184-001b864730c0"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-64f15fe75071>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import boto3\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import fitz\n",
        "from botocore.exceptions import ClientError\n",
        "\n",
        "# API credentials\n",
        "access_key = \"Insert Key Here\"\n",
        "access_secret = \"Insert Secret Here\"\n",
        "\n",
        "cleaned_content = \"\"\n",
        "\n",
        "files = {\n",
        "    \"example_patients\": \"/content/aphasiapatient - ENGLISH - aphasiapatient (1).pdf\",\n",
        "}\n",
        "\n",
        "# Function to read PDF files\n",
        "def read_pdf(file_path):\n",
        "    document = fitz.open(file_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(document)):\n",
        "        page = document.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "example_patients = read_pdf(files[\"example_patients\"])\n",
        "\n",
        "def preprocess_transcript(file_content):\n",
        "    # Split the content into lines\n",
        "    lines = file_content.split('\\n')\n",
        "\n",
        "    # Keep only lines starting with '*INV:' or '*PAR:', and replace the asterisk with the label\n",
        "    cleaned_lines = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line.startswith('*INV:'):\n",
        "            cleaned_lines.append('INV: ' + line[5:].strip())\n",
        "        elif line.startswith('*PAR:'):\n",
        "            cleaned_lines.append('PAR: ' + line[5:].strip())\n",
        "\n",
        "    # Join the cleaned lines back into a single string\n",
        "    cleaned_content = '\\n'.join(cleaned_lines)\n",
        "\n",
        "    return cleaned_content\n",
        "def clean_transcript(input_text):\n",
        "    # Keep only lines with speaker labels (*INV:, *PAR:) and their content\n",
        "    cleaned_lines = re.findall(r'^\\*[A-Z]+:.*$', input_text, re.MULTILINE)\n",
        "    # Remove various artifacts and clean up the lines\n",
        "    cleaned_lines = [re.sub(r'\\d+_\\d+$|•\\d+_\\d+•|\\[.*?\\]|&=.*?(?:\\s|$)|&-\\w+|\\+<|\\(\\.\\.\\)|\\.\\.\\.|‡', '', line) for line in cleaned_lines]\n",
        "    # Remove leading/trailing whitespace and any remaining punctuation at the end\n",
        "    cleaned_lines = [re.sub(r'^\\s+|\\s+$|[,\\.!?]+$', '', line) for line in cleaned_lines]\n",
        "    # Remove empty lines and lines with only punctuation/spaces\n",
        "    cleaned_lines = [line for line in cleaned_lines if re.search(r'[a-zA-Z]', line)]\n",
        "    return '\\n'.join(cleaned_lines)\n",
        "\n",
        "# Function to call Bedrock API with retry logic\n",
        "def call_bedrock(prompt, max_retries=3):\n",
        "    retries = 0\n",
        "    while retries <= max_retries:\n",
        "        try:\n",
        "            bedrock = boto3.client(service_name='bedrock-runtime',\n",
        "                                   region_name='us-east-1',\n",
        "                                   aws_access_key_id=access_key,\n",
        "                                   aws_secret_access_key=access_secret)\n",
        "\n",
        "            body = json.dumps({\n",
        "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
        "                \"max_tokens\": 4096,\n",
        "                \"messages\": [\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\n",
        "                                \"type\": \"text\",\n",
        "                                \"text\": prompt\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                ],\n",
        "                \"temperature\": 0.1,\n",
        "                \"top_p\": 1\n",
        "            })\n",
        "\n",
        "            modelId = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
        "            accept = 'application/json'\n",
        "            contentType = 'application/json'\n",
        "\n",
        "            response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
        "            response_body = json.loads(response.get('body').read())\n",
        "            text = response_body['content'][0]['text']\n",
        "            return text\n",
        "        except ClientError as e:\n",
        "            if e.response['Error']['Code'] == 'ThrottlingException':\n",
        "                if retries < max_retries:\n",
        "                    wait_time = 120  # 2 minutes\n",
        "                    st.warning(f\"Rate limit reached. Waiting for {wait_time} seconds before retrying...\")\n",
        "                    time.sleep(wait_time)\n",
        "                    retries += 1\n",
        "                else:\n",
        "                    raise Exception(\"Max retries reached. Unable to process request.\")\n",
        "            else:\n",
        "                raise e\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error in call_bedrock: {str(e)}\")\n",
        "\n",
        "\n",
        "# Streamlit UI\n",
        "st.set_page_config(page_title=\"Aphasia Analysis\", page_icon=\":brain:\")\n",
        "\n",
        "st.title(\"Aphasia Type and WAB Score Analysis\")\n",
        "\n",
        "uploaded_files = st.file_uploader(\"Choose files\", type=[\"txt\", \"rtf\", \"cha\"], accept_multiple_files=True)\n",
        "\n",
        "instructions = f\"\"\"\n",
        "The factors of Aphasic speech that I need counted are. Provide the number of occurrences for each patient. Make sure you only look at the lines that start with @PAR:\n",
        "\n",
        "1. Non-fluent speech: Slow, halting speech with frequent pauses\n",
        "2. Word retrieval issues: Use of fillers, circumlocutions, semantic paraphasias\n",
        "3. Grammatical errors: Incorrect function words, verb tenses, simplified sentences\n",
        "4. Repetitions and revisions: Repeating words/phrases due to word-finding difficulties\n",
        "5. Paraphasias: Unintended word substitutions (semantic or phonemic)\n",
        "6. Neologisms: Creation of non-existent words\n",
        "7. Perseveration: Unintentional repetition of words/phrases\n",
        "8. Comprehension issues: Difficulty understanding complex sentences or fast speech\n",
        "\n",
        "\n",
        "Summary of Evaluation Results:\n",
        "Write a description for each of these factors in the patient.\n",
        "\n",
        "Fluency: Assessment of the patient’s fluency, including spontaneous speech, language sample analysis, and subtest scores.\n",
        "Comprehension: Evaluation of auditory comprehension, word recognition, and the ability to follow commands.\n",
        "Naming: Results from naming tests, including spontaneous naming, phonological errors, and performance on naming tasks.\n",
        "Semantic Processing: Evaluation of the patient’s ability to process semantic information.\n",
        "Repetition: Assessment of the ability to repeat words, phrases, and non-words.\n",
        "\n",
        "Fluency: (insert score here; scale of 0-10) Remember that this can be below 5\n",
        "Comprehension: (insert score here; scale of 0-10) Remember that this can be below 5\n",
        "Repetition: (insert score here; scale of 0-10)Remember that this can be below 5\n",
        "Naming: (insert score here; scale of 0-10) Remember that this can be below 5\n",
        "\n",
        "When I refer to the spreadsheet, use the {example_patients} file to compare the transcript I am giving you. This is a file of aphasic patients of all types, ages, genders, and range of severity. Based on your comparison to these patients, determine the aphasia type and WAB score.\n",
        "\n",
        "Broca's Aphasia:\n",
        "- Spontaneous speech: Non-fluent, effortful, telegraphic\n",
        "- Auditory comprehension: Relatively preserved, especially for simple material\n",
        "- Repetition: Impaired\n",
        "- Naming: Difficult, with frequent pauses\n",
        "- Reading: Often preserved for single words, difficulty with sentences\n",
        "- Writing: Severely impaired, similar to speech output\n",
        "\n",
        "Typical errors: Agrammatism, word-finding difficulties, articulation problems\n",
        "\n",
        "Associated brain region: Posterior inferior frontal gyrus (Broca's area)\n",
        "\n",
        "Case example: A 55-year-old right-handed man presents with halting, effortful speech following a left frontal lobe stroke. He can understand simple commands but struggles to produce complete sentences, often omitting function words and inflections.\n",
        "\n",
        "Wernicke's Aphasia:\n",
        "- Spontaneous speech: Fluent, often with excessive output\n",
        "- Auditory comprehension: Severely impaired\n",
        "- Repetition: Impaired\n",
        "- Naming: Impaired, with semantic paraphasias\n",
        "- Reading: Often impaired, especially for comprehension\n",
        "- Writing: Impaired, with semantic errors and jargon\n",
        "\n",
        "Typical errors: Semantic paraphasias, neologisms, jargon\n",
        "\n",
        "Associated brain region: Posterior superior temporal gyrus (Wernicke's area)\n",
        "\n",
        "Case example: A 70-year-old woman presents with fluent but largely incomprehensible speech following a left temporal lobe stroke. She speaks at length but with little meaningful content, and has significant difficulty understanding even simple commands.\n",
        "\n",
        "Conduction Aphasia:\n",
        "- Spontaneous speech: Fluent with phonemic paraphasias\n",
        "- Auditory comprehension: Relatively preserved\n",
        "- Repetition: Severely impaired\n",
        "- Naming: Mildly impaired, with phonemic errors\n",
        "- Reading: Often preserved, especially for comprehension\n",
        "- Writing: Impaired, with phonemic errors\n",
        "\n",
        "Typical errors: Frequent phonemic paraphasias, repetition attempts and self-corrections\n",
        "\n",
        "Associated brain region: Arcuate fasciculus or left supramarginal gyrus\n",
        "\n",
        "Case example: A 62-year-old woman presents with fluent speech but significant difficulty repeating words and phrases. She understands spoken language well but makes frequent sound-based errors in her speech, often attempting to correct herself.\n",
        "\n",
        "Global Aphasia:\n",
        "- Spontaneous speech: Severely impaired, often limited to stereotyped utterances\n",
        "- Auditory comprehension: Severely impaired\n",
        "- Repetition: Severely impaired\n",
        "- Naming: Severely impaired\n",
        "- Reading: Severely impaired\n",
        "- Writing: Severely impaired\n",
        "\n",
        "Typical errors: Minimal meaningful verbal output, severe impairment across all language domains\n",
        "\n",
        "Associated brain region: Extensive damage to perisylvian language areas\n",
        "\n",
        "Case example: A 75-year-old man presents with almost no meaningful speech output following a large left hemisphere stroke. He is unable to follow commands, name objects, or engage in any form of written language.\n",
        "\n",
        "Anomic Aphasia:\n",
        "- Spontaneous speech: Fluent but with word-finding pauses\n",
        "- Auditory comprehension: Preserved\n",
        "- Repetition: Relatively preserved\n",
        "- Naming: Significantly impaired\n",
        "- Reading: Often preserved\n",
        "- Writing: Mild to moderate impairment, mainly in word retrieval\n",
        "\n",
        "Typical errors: Frequent word-finding difficulties, circumlocutions\n",
        "\n",
        "Associated brain region: Various, often involving the angular gyrus or temporal-parietal junction\n",
        "\n",
        "Case example: A 58-year-old woman presents with fluent speech but frequent pauses as she struggles to retrieve specific words, especially nouns. Her comprehension and repetition abilities are intact.\n",
        "\n",
        "Transcortical Sensory Aphasia:\n",
        "- Spontaneous speech: Fluent but often empty or irrelevant\n",
        "- Auditory comprehension: Impaired\n",
        "- Repetition: Preserved (key distinguishing feature)\n",
        "- Naming: Impaired\n",
        "- Reading: Impaired comprehension\n",
        "- Writing: Impaired\n",
        "\n",
        "Typical errors: Poor comprehension with preserved repetition, semantic paraphasias\n",
        "\n",
        "Associated brain region: Watershed area between middle cerebral and posterior cerebral arteries\n",
        "\n",
        "Case example: A 68-year-old man presents with fluent but often irrelevant speech. He has difficulty understanding complex commands but can repeat even long sentences accurately.\n",
        "\n",
        "Transcortical Motor Aphasia:\n",
        "- Spontaneous speech: Non-fluent, reduced output\n",
        "- Auditory comprehension: Relatively preserved\n",
        "- Repetition: Preserved\n",
        "- Naming: Impaired\n",
        "- Reading: Often preserved for comprehension\n",
        "- Writing: Impaired\n",
        "\n",
        "Typical errors: Reduced speech initiation, preserved repetition\n",
        "\n",
        "Associated brain region: Frontal lobe, anterior or superior to Broca's area\n",
        "\n",
        "Case example: A 72-year-old woman presents with reduced speech output and difficulty initiating conversation. However, she can repeat phrases and sentences without difficulty and shows good comprehension.\n",
        "1. Fluency vs. Non-fluency\n",
        "   - Fluent: Wernicke's, Conduction, Anomic, Transcortical Sensory\n",
        "   - Non-fluent: Broca's, Global, Transcortical Motor\n",
        "\n",
        "2. Comprehension\n",
        "   - Good: Broca's, Conduction, Anomic, Transcortical Motor\n",
        "   - Poor: Wernicke's, Global, Transcortical Sensory\n",
        "\n",
        "3. Repetition\n",
        "   - Impaired: Broca's, Wernicke's, Conduction, Global\n",
        "   - Preserved: Anomic, Transcortical Sensory, Transcortical Motor\n",
        "\n",
        "4. Naming\n",
        "   - Severely Impaired: Wernicke's, Global, Anomic\n",
        "   - Moderately Impaired: Broca's, Conduction, Transcortical types\n",
        "\n",
        "Every type of aphasia is equally common and it differs on a patient by patient basis.\n",
        "Provide your classification and a detailed justification based on the patient's performance across all domains.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Format the answer\n",
        "answer_info = f\"\"\"\n",
        "Transcript: {cleaned_content}. Look only at the PAR lines for this. compare the entire transcript to every line of the spreadsheet. dont compere teh words, but compare the speech patterns and the symprtoms of speech. the words are the same for all of them.\n",
        "\n",
        "\n",
        "Can you analyze the entire spreadsheet. And every row\n",
        "Compare the transcript to the spreadsheet. Give me the top 3 rows that you think align with this patient in transcript. Look only at the PAR lines for this\n",
        "Look only at the PAR lines for this. Each row has language, gender, aphasia type, WAB Score, Transcript. Compare the symptoms of the transcript to the last column of each row in this file to find which symptoms match the spreadsheet. Then, look at the other information.\n",
        "List:\n",
        "Look only at the PAR lines for this. I want you to compare the entire sections. Look towards the ending of the transcript in fact. there is more content there\n",
        "(row  in the spreadsheet; Display the first 3 lines and the line that you think connects the transcript the best)\n",
        "(row  in the spreadsheet; Display the first 3 lines and the line that you think connects the transcript the best)\n",
        "(row  in the spreadsheet; Display the first 3 lines and the line that you think connects the transcript the best)\n",
        "\n",
        "Symptoms:\n",
        "You seem to be confusing word retreival issues and paraphasias/neologisms/Comprehension issues. Try to fixt this\n",
        "\n",
        "\n",
        "1. Fluency of speech: Is the speech effortful and non-fluent (like in Broca's aphasia) or more fluent but with errors (like in conduction or Wernicke's aphasia)? (number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "2. Comprehension abilities: How well does the patient understand spoken language? This helps differentiate receptive (e.g. Wernicke's) from expressive (e.g. Broca's) aphasias.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "3. Repetition skills: Ability to repeat words and phrases is a key diagnostic feature, particularly impaired in conduction aphasia.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "4. Naming abilities: Word-finding difficulties are common in many aphasias, but the nature and severity can vary.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "5. Presence and types of paraphasias: Phonemic paraphasias (sound errors) vs. semantic paraphasias (meaning-related errors) can point to different aphasia types.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "6. Awareness of errors: Whether the patient recognizes and attempts to correct their errors.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "7. Agrammatism: The degree to which grammatical structure is impaired.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "8. Automatic speech: Ability to produce overlearned phrases or sequences.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "9. Reading and writing abilities: These can be differentially affected in various aphasia types.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "\n",
        "10. Overall pattern of strengths and weaknesses across language domains.(number of occurrences), severity percentile (numerical)\n",
        "\n",
        "For accurate diagnosis, it's crucial to consider the full pattern of deficits and preserved abilities across all these areas, rather than relying too heavily on any single feature. A comprehensive language assessment considering all these factors is essential for proper aphasia classification.\n",
        "\n",
        "Symptom Severity Rating:\n",
        "Rate the following factors on a scale of 0-10:\n",
        "\n",
        "Fluency: (insert score here; scale of 0-10)\n",
        "Comprehension: (insert score here; scale of 0-10)\n",
        "Repetition: (insert score here; scale of 0-10)\n",
        "Naming: (insert score here; scale of 0-10)\n",
        "\n",
        "Global Aphasia\n",
        "\n",
        "Fluency: 0-5\n",
        "Comprehension: 0-3.9\n",
        "Repetition: 0-4.9\n",
        "Naming: 0-6\n",
        "\n",
        "\n",
        "Broca's Aphasia\n",
        "\n",
        "Fluency: 0-9\n",
        "Comprehension: 5-10\n",
        "Repetition: 0-6\n",
        "Naming: 0-8\n",
        "\n",
        "Wernicke's Aphasia\n",
        "\n",
        "Fluency: 0-3\n",
        "Comprehension: 0-9\n",
        "Repetition: 3-10\n",
        "Naming: 0-6\n",
        "\n",
        "\n",
        "Transcortical Motor Aphasia\n",
        "\n",
        "Fluency: 0-5\n",
        "Comprehension: 4-10\n",
        "Repetition: 8-10\n",
        "Naming: 0-8\n",
        "\n",
        "\n",
        "Transcortical Sensory Aphasia\n",
        "\n",
        "Fluency: 5-10\n",
        "Comprehension: 0-6.9\n",
        "Repetition: 8-10\n",
        "Naming: 0-9\n",
        "\n",
        "\n",
        "Mixed Transcortical Aphasia\n",
        "\n",
        "Fluency: 5-10\n",
        "Comprehension: 0-6.9\n",
        "Repetition: 8-10\n",
        "Naming: 0-9\n",
        "\n",
        "\n",
        "Conduction Aphasia\n",
        "\n",
        "Fluency: 5-10\n",
        "Comprehension: 7-10\n",
        "Repetition: 0-8\n",
        "Naming: 0-9\n",
        "\n",
        "Anomic Aphasia\n",
        "\n",
        "Fluency: 7-10\n",
        "Comprehension: 8-10\n",
        "Repetition: 8-10\n",
        "Naming: 0-9\n",
        "\n",
        "Aphasia Classification:\n",
        "1. Is speech fluent?\n",
        "A fluency disorder is an interruption in the flow of speaking characterized by atypical rate, rhythm, and disfluencies (e.g., repetitions of sounds, syllables, words, and phrases; sound prolongations; and blocks), which may also be accompanied by excessive tension, speaking avoidance, struggle behaviors, and secondary mannerisms (American Speech-Language-Hearing Association [ASHA], 1993). People with fluency disorders also frequently experience psychological, emotional, social, and functional impacts as a result of their communication disorder (Tichenor & Yaruss, 2019a).\n",
        "Make sure that you use the timestamps at the end of the transcripts to do this.\n",
        "   Yes -> Check comprehension\n",
        "   No -> Check comprehension for non-fluent types\n",
        "\n",
        "2. Fluent types:\n",
        "   - Poor comprehension, poor repetition -> Wernicke's\n",
        "   - Poor comprehension, good repetition -> Transcortical Sensory\n",
        "   - Good comprehension, poor repetition -> Conduction\n",
        "   - Good comprehension, good repetition -> Anomic\n",
        "\n",
        "3. Non-fluent types:\n",
        "   - Poor comprehension -> Global\n",
        "   - Good comprehension, poor repetition -> Broca's\n",
        "   - Good comprehension, good repetition -> Transcortical Motor\n",
        "\n",
        "Aphasia Classification Trial: (insert type of aphasia)\n",
        "\n",
        "Provide your classification with detailed justification based on performance across all domains.\n",
        "If all of the symptoms are less than 7 occurances, there is no aphasia\n",
        "It is important to look at not just the symptoms but thte content of the speech too. Is what the patient is saying make sense? Do they loose track of the topic? Are they frustrated?\n",
        "Initial Aphasia Diagnosis:\n",
        "Provide 4 types of aphasia it could be. Transcortical Motor Aphasia. Don't forget about  Wernicke's aphasia orGlobal aphasia or Transcortical Motor Aphasia or Transcortical Sensory Aphasia\n",
        "Initial Aphasia Types. For each of these types, compare back to the spreadsheet and check this transcript agaiinst every one of the transcripts for that type of aphasia. I dont\n",
        "Wernicke's Aphasia\n",
        "(insert type of aphasia or no aphasia)\n",
        "(insert type of aphasia or no aphasia)\n",
        "Considerations for Alternate Aphasias:\n",
        "List reasons for considering each alternate aphasia. Include detailed comparisons and rationale.\n",
        "Reevaluate the initial diagnosis if substantial evidence supports an alternate type.\n",
        "Type of aphasia: Present this in the format of \"Type of Aphasia: (insert aphasia type here)\"\n",
        "\n",
        "Provide a confidence score as well. If confidence is below 90% it is another type of aphasia.\n",
        "Keep trying to figure it out.\n",
        "\n",
        "Compare the transcript to the spreadsheet to determine aphasia type and WAB score.\n",
        "\n",
        "WAB Score Determination:\n",
        "\n",
        "Spontaneous Speech:\n",
        "Content\n",
        "Fluency\n",
        "\n",
        "\n",
        "Auditory Verbal Comprehension:\n",
        "Yes/No Questions\n",
        "Auditory Word Recognition\n",
        "\n",
        "\n",
        "Sequential Commands\n",
        "Repetition:\n",
        "Words\n",
        "Phrases\n",
        "Sentences\n",
        "\n",
        "\n",
        "Naming and Word Finding:\n",
        "Object Naming\n",
        "Word Fluency\n",
        "Sentence Completion\n",
        "Responsive Speech\n",
        "\n",
        "\n",
        "Aphasia Quotient (AQ): Overall score indicating the severity of aphasia.\n",
        "\n",
        "\n",
        "1. Start at WAB score of 5; not 50 because wab can be lower than 50\n",
        "2. Increase in 10-point intervals, comparing to the spreadsheet. Go all the way to 100\n",
        "3. Provide reasoning for each step\n",
        "4. When a suitable interval is found after going all the way to 100, refine by 5-point, then 1-point increments, then 0.1 point increments.\n",
        "5. Remember: WAB scores can be below 60 or above 93.8 (no aphasia)\n",
        "6. Determine a score based on the the following studies: The WAB has four subdomains: (1) spontaneous speech; (2) auditory comprehension; (3) repetition; and (4) naming designed to determine the presence of aphasia and judge the type of linguistic deficit and measure the severity of language impairment. The full score of spontaneous speech is 20, including fluency and content of information. The 200 points of auditory comprehension consist of 60 points of Yes–No questions, 60 points of auditory word recognition, and 80 points of sequential commands. The total score of repetition is 100. A total of 100 points are given for naming, including 60 points for object naming, 20 points for fluency of words, 10 points for sentence completion, and 10 points for responsive speech. The calculation formula of the aphasia quotient is “AQ = (Spontaneous + Comprehension ÷ 20 + Repetition ÷ 10 + Naming ÷ 10) × 2”. All of the items result in a range of possible scores from 0 to 100. Combined with the clinical data of stroke patients, those whose aphasia quotient is less than 93.8 can be judged as aphasia, and the smaller the aphasia quotient, the more serious the aphasia. In addition, the WAB-AQ is commonly used to measure recovery, although there is a discrepancy between clinical impression and WAB in the classification of aphasia, the superiority of WAB is that it can quantify language damage.\n",
        "7. Determine a score by comparing this patient with the participants in the spreadsheet.\n",
        "8. Compare the 3 scores and determine a final score.\n",
        "\n",
        "Show your thoughts below:\n",
        "WAB Score 1:\n",
        "WAB Score 2:\n",
        "WAB Score 3:\n",
        "\n",
        "WAB Score: Present this in the format of \"Estimated WAB Score: (insert number on scale of 0-100 here)\". Note that WAB scores can range widely and are not limited to 50-80.\n",
        "IMPORTANT: WAB SCORE IS NOT RELATED TO TYPE OF APHASIA\n",
        "\n",
        "Final Type of aphasia: Based on the WAB score and the original aphasia type, make any changes that you think would be mandatory. If you are borderline 93.8, check if the no aphasia option makes sense. Use the spreadsheet\n",
        "\n",
        "Treatment Suggestions:\n",
        "Provide treatment suggestions in a list, with a description for each therapy. Include a detailed explanation for choosing each treatment, citing the aphasia manual and patient symptoms.\n",
        "\n",
        "\n",
        "Explanation:\n",
        "(Provide a detailed explanation here for the therapist, ensuring it is useful and practical, citing the manual where appropriate).\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "if uploaded_files:\n",
        "    for uploaded_file in uploaded_files:\n",
        "        st.write(f\"Processing file: {uploaded_file.name}\")\n",
        "        file_content = uploaded_file.read().decode(\"utf-8\")\n",
        "        cleaned_content = clean_transcript(file_content)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a speech pathologist, a healthcare professional who specializes in evaluating, diagnosing, and treating communication disorders, including speech, language, cognitive-communication, voice, swallowing, and fluency disorders. Your role is to help patients improve their speech and communication skills through various therapeutic techniques and exercises.\n",
        "\n",
        "In this scenario, you will be working with a patient who has the following speech disorder or issue:\n",
        "\n",
        "Aphasia\n",
        "\n",
        "What is aphasia?\n",
        "Aphasia is a disorder that results from damage to portions of the brain that are responsible for language. For most people, these areas are on the left side of the brain. Aphasia usually occurs suddenly, often following a stroke or head injury, but it may also develop slowly, as the result of a brain tumor or a progressive neurological disease. The disorder impairs the expression and understanding of language as well as reading and writing. Aphasia may co-occur with speech disorders, such as dysarthria or apraxia of speech, which also result from brain damage.\n",
        "\n",
        "Who can acquire aphasia?\n",
        "Most people who have aphasia are middle-aged or older, but anyone can acquire it, including young children. About 1 million people in the United States currently have aphasia, and nearly 180,000 Americans acquire it each year, according to the National Aphasia Association.\n",
        "\n",
        "What causes aphasia?\n",
        "Aphasia is caused by damage to one or more of the language areas of the brain. Most often, the cause of the brain injury is a stroke. A stroke occurs when a blood clot or a leaking or burst vessel cuts off blood flow to part of the brain. Brain cells die when they do not receive their normal supply of blood, which carries oxygen and important nutrients. Other causes of brain injury are severe blows to the head, brain tumors, gunshot wounds, brain infections, and progressive neurological disorders, such as Alzheimer's disease.\n",
        "\n",
        "use the instructions to do the full analysis: {instructions}\n",
        "\n",
        "cite specific content from the information below to justify your decisions\n",
        "\n",
        "<dialogue>\n",
        "Focus on the *PAR lines\n",
        "Remember that WAB score is not related to Aphasia type. Every WAB score can be any aphasia and every aphasia can have a range of WAB scores\n",
        "{cleaned_content}\n",
        "</dialogue>\n",
        "\n",
        "Based on the information provided, please do the following:\n",
        "\n",
        "Focus on the *PAR lines\n",
        "Do this using {answer_info}\n",
        "\n",
        "Remember, your goal is to provide a comprehensive and supportive therapy experience for the patient, helping them to improve their speech and communication skills and build their confidence in the process. Use your expertise and empathy to guide them through this journey.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = call_bedrock(prompt)\n",
        "            st.write(response)\n",
        "\n",
        "            # Add a pause to avoid rate limiting\n",
        "            time.sleep(2)  # Adjust this value as needed\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred while processing the file {uploaded_file.name}: {str(e)}\")\n",
        "\n",
        "else:\n",
        "    st.info(\"Please upload files to analyze.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4ANTq_RvrVw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3eG5jZ4pIVjy"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
